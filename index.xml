<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Driftless Data on Driftless Data</title>
    <link>http://driftlessdata.space/</link>
    <description>Recent content in Driftless Data on Driftless Data</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <copyright>&amp;copy; 2017 Silas Bergen</copyright>
    <lastBuildDate>Sun, 15 Oct 2017 00:00:00 -0500</lastBuildDate>
    <atom:link href="/" rel="self" type="application/rss+xml" />
    
    <item>
      <title>On elementary perceptual tasks</title>
      <link>http://driftlessdata.space/post/on-epts/</link>
      <pubDate>Tue, 19 Dec 2017 00:00:00 +0000</pubDate>
      
      <guid>http://driftlessdata.space/post/on-epts/</guid>
      <description>&lt;p&gt;One of the first concepts I talk about in my &lt;a href=&#34;../../courses/dsci310/dsci310-home/&#34;&gt;data visualization course&lt;/a&gt; is the idea of the &lt;a href=&#34;http://info.slis.indiana.edu/~katy/S637-S11/cleveland84.pdf&#34;&gt;&lt;em&gt;elementary perceptual task&lt;/em&gt;&lt;/a&gt; (EPT), an idea explored in depth by visualization pioneers William S. Cleveland and Robert McGill. Essentially, EPTs are visual building blocks for comparing quantities. The EPTs are summarized nicely in Figure 1 from &lt;a href=&#34;http://info.slis.indiana.edu/~katy/S637-S11/cleveland84.pdf&#34;&gt;&lt;em&gt;Graphical Perception: Theory, Experiementation, and Application to the Development of Graphical Methods&lt;/em&gt;&lt;/a&gt;:&lt;/p&gt;
&lt;center&gt;
&lt;figure&gt;
&lt;img src = &#34;../../img/ept.JPG&#34; width=&#34;500&#34;&gt;
&lt;/figure&gt;
&lt;/center&gt;
&lt;p&gt;For example, looking at the two dots in the upper-left pane, we perceive that the top dot represents a larger quantity than the bottom dot, because it is &lt;em&gt;higher on a common scale&lt;/em&gt; than the bottom dot. In the middle panel (“Angle”), we perceive that the angle on the right represents a larger quantity than the angle on the left, since it is a larger angle.&lt;/p&gt;
&lt;p&gt;A fundamental finding from the article is that, as humans, we are better at some elementary perceptual tasks than at others. We more accurately and easily compare quantities if they are mapped using &lt;strong&gt;&lt;em&gt;position on a common scale&lt;/em&gt;&lt;/strong&gt; than if they are mapped using &lt;strong&gt;&lt;em&gt;length&lt;/em&gt;&lt;/strong&gt;, &lt;strong&gt;&lt;em&gt;angle&lt;/em&gt;&lt;/strong&gt; or &lt;strong&gt;&lt;em&gt;size&lt;/em&gt;&lt;/strong&gt;. In fact, Cleveland and McGill came up with the following ranking of EPTs we perform most efficiently when visually comparing quantities:&lt;/p&gt;
&lt;ol style=&#34;list-style-type: decimal&#34;&gt;
&lt;li&gt;&lt;strong&gt;&lt;em&gt;Position along a common scale;&lt;/em&gt;&lt;/strong&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;&lt;em&gt;Position along misaligned scales;&lt;/em&gt;&lt;/strong&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;&lt;em&gt;Length;&lt;/em&gt;&lt;/strong&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;&lt;em&gt;Angles;&lt;/em&gt;&lt;/strong&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;&lt;em&gt;Size;&lt;/em&gt;&lt;/strong&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;&lt;em&gt;Color&lt;/em&gt;&lt;/strong&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;Recently, I wrote &lt;a href=&#34;../income-gestalt/&#34;&gt;a post&lt;/a&gt; discussing a few of the Gestalt principles and illustrating them with some ACS data on income, sex, and field of degree. The Gestalt principles describe how we perceive patterns, while the EPTs describe how we most efficiently compare quantities. In this post, we continue to use income data from the American Community Survey to illustrate EPTs.&lt;/p&gt;
&lt;div id=&#34;case-study-employment-level-by-sex&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Case study: employment level by sex&lt;/h3&gt;
&lt;p&gt;In my &lt;a href=&#34;../income-gestalt/&#34;&gt;previous post&lt;/a&gt;, it was apparent that a gender gap in average annual income persisted even when accounting for year, highest degree, and field of degree. Another important factor that explains income is level of employment, as measured by average hours worked per week. The data for this example are once again &lt;a href=&#34;https://www.dropbox.com/s/0wmr2brny428lo3/ACS-income-data-aggregated.csv?dl=0&#34;&gt;aggregated ACS data&lt;/a&gt; from the &lt;a href=&#34;https://usa.ipums.org/usa-action/variables/group&#34;&gt;IPUMS USA&lt;/a&gt; extract system, filtered to include only employed individuals with at least a Bachelor’s degree.&lt;/p&gt;
&lt;p&gt;Let’s start by sticking yet another pitchfork in the favorite straw man of data visualization: the pie chart. With an understanding of EPTs, we can begin to understand why pie charts are &lt;a href=&#34;http://www.businessinsider.com/pie-charts-are-the-worst-2013-6&#34;&gt;so&lt;/a&gt; &lt;a href=&#34;https://blog.funnel.io/why-we-dont-use-pie-charts-and-some-tips-on-better-data-visualizations&#34;&gt;maligned&lt;/a&gt; in the data visualization community. Take a look at the graph below, and try to determine how the percent of females working full time changes over the years:&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;http://driftlessdata.space/post/on-epts_files/figure-html/unnamed-chunk-2-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;Pie charts are fine for visualizing &lt;em&gt;parts of a single whole&lt;/em&gt; (it is easy to tell that, in any given year, a majority of women work full time), but they make it difficult to compare parts of &lt;em&gt;different wholes&lt;/em&gt; (how the percent working full time changes over the years). This comparison is difficult to make because we are comparing &lt;strong&gt;&lt;em&gt;angles&lt;/em&gt;&lt;/strong&gt;, an elementary perceptual task that we do not perform very efficiently or well. Here are the same data, different graph:&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;http://driftlessdata.space/post/on-epts_files/figure-html/unnamed-chunk-3-1.png&#34; width=&#34;480&#34; /&gt;&lt;/p&gt;
&lt;p&gt;Notice that it’s now much easier to discern that the percent of females working 40 or more hours per week is increasing over time, while the percent of females working part-time is decreasing. We now compare the &lt;strong&gt;&lt;em&gt;position&lt;/em&gt;&lt;/strong&gt; of the quantities denoted by points along a common scale (the vertical Y-axis), rather than the &lt;strong&gt;&lt;em&gt;angle&lt;/em&gt;&lt;/strong&gt;. We can also still clearly see that in each year, a majority of women work full time, by comparing the points along the common vertical scale within a single year.&lt;/p&gt;
&lt;p&gt;Let’s turn now to comparing the hours worked for females to males, in 2016 alone. We’ll use a bar chart for this: &lt;img src=&#34;http://driftlessdata.space/post/on-epts_files/figure-html/unnamed-chunk-4-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;What EPT are we using to compare the percents? It is &lt;a href=&#34;http://flowingdata.com/2010/03/20/graphical-perception-learn-the-fundamentals-first/&#34;&gt;tempting to think&lt;/a&gt; that when we compare quantities in bar charts, we are comparing &lt;strong&gt;&lt;em&gt;lengths&lt;/em&gt;&lt;/strong&gt; of the bars. But this is not the primary EPT we are using, here. We are really comparing &lt;strong&gt;&lt;em&gt;position along a comon scale&lt;/em&gt;&lt;/strong&gt; once again. This is clearer if we represent the quantities not as bars, but as points. We are carrying out the same exact elementary perceptual task to compare the percents:&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;http://driftlessdata.space/post/on-epts_files/figure-html/unnamed-chunk-5-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;This “point chart” has a much better &lt;a href=&#34;http://www.infovis-wiki.net/index.php/Data-Ink_Ratio&#34;&gt;&lt;em&gt;data-to-ink ratio&lt;/em&gt;&lt;/a&gt; than the bar chart, a concept coined by &lt;a href=&#34;https://www.edwardtufte.com/tufte/&#34;&gt;Edward Tufte&lt;/a&gt;. One could argue that it is cleaner and more succinct; better emphasizes the data; and exploits the same exact EPT as the bar chart. Why, then, are bar charts so pervasive while these “point charts” are not? I think the reason is two-fold. First, we just have a comfort level with bar charts. The point of a data visualization is communication: if we can communicate quicker with a more familiar medium, that has advantages. Second, perhaps more importantly, when we see points we immediately start looking for trends. &lt;strong&gt;&lt;em&gt;Direction&lt;/em&gt;&lt;/strong&gt; is one of Cleveland and McGill’s EPTs; we are more inclined to try to visually connect points than the tops of bars. However, we shouldn’t always connect points, especially if the categories on the horizontal have no sense of ordering (for example, if “race,” which has no ordering, was on the horizontal instead of employment level).&lt;/p&gt;
&lt;p&gt;For these reasons, let’s go back to the bar chart.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;http://driftlessdata.space/post/on-epts_files/figure-html/unnamed-chunk-6-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;What comparison does this encourage us to make? Because of the two separate panels for females and males (the &lt;a href=&#34;../income-gestalt/&#34;&gt;Gestalt principle&lt;/a&gt; of &lt;strong&gt;&lt;em&gt;enclosure&lt;/em&gt;&lt;/strong&gt;), the encouraged comparisons seem to be &lt;em&gt;within&lt;/em&gt; sex: among females, a much greater percent of them work 40 or more hours a week than are in the other 3 categories; the same can be said for males. It is more likely that we want to compare &lt;em&gt;across&lt;/em&gt; sex: assess differences between males and females in work time. How can we better encourage this comparison? One approach is to group by hours worked, rather than sex:&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;http://driftlessdata.space/post/on-epts_files/figure-html/unnamed-chunk-7-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;This better encourages us to compare females to males, but it still requires us to jump from panel to panel to make that comparison for each employment level. Another major problem with the above graph is that the percents are calculated by conditioning &lt;em&gt;on sex&lt;/em&gt;, whereas the facets make it appear the conditioning is &lt;em&gt;on employment level&lt;/em&gt;. For example, when we see two bars representing percents in a single panel, we are tempted to think that the total height of the two bars is 100%, which is clearly not the case. The “whole” out of which the percents are taken is not at all clear.&lt;/p&gt;
&lt;p&gt;Here’s one last take: a &lt;em&gt;stacked bar chart&lt;/em&gt;.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;http://driftlessdata.space/post/on-epts_files/figure-html/unnamed-chunk-8-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;This accomplishes two objectives previous visualizations lacked: A) making the most important comparison obvious (comparing females to males), and B) making obvious “the whole” out of which the percents are taken. Note that when comparing females to males, we use &lt;strong&gt;&lt;em&gt;position along the common (vertical) axis&lt;/em&gt;&lt;/strong&gt; to compare the percents who work 40 or more hours (by determining which dark blue bar extends &lt;em&gt;highest&lt;/em&gt; on the vertical); and to compare the percents who work 20 or fewer hours (by determining which white bar extends &lt;em&gt;lowest&lt;/em&gt; on the vertical). However, to compare the percent who work 21-30 or 31-39 across sex, we use &lt;strong&gt;&lt;em&gt;length&lt;/em&gt;&lt;/strong&gt;, since the middle bars do not share a common baseline. Although we sacrifice making comparisons using &lt;strong&gt;&lt;em&gt;position along a common scale&lt;/em&gt;&lt;/strong&gt; with the stacked bar chart for two of the employment levels, we make up for it with fewer facets; more succinct presentation; and more obvious important comparisons.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;data-notes&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Data notes&lt;/h3&gt;
&lt;p&gt;Some of the averages in the &lt;a href=&#34;https://www.dropbox.com/s/0wmr2brny428lo3/ACS-income-data-aggregated.csv?dl=0&#34;&gt;data set&lt;/a&gt; I used for this post (for example, average income for Alabaman males with a doctoral degree in 2009) are based on very few observations, and should be taken with a very large grain of salt. Another brief data note: to aggregate this data set further, it is important to weight by the &lt;code&gt;N&lt;/code&gt; column, which indicates how many individuals in the population the average for that row represents.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;r-code&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;R code&lt;/h3&gt;
&lt;p&gt;If interested, here is the R code for creating the bar charts.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;library(ggplot2)
library(dplyr)

#Read in the data; assuming current working directory houses the .csv file
tmp &amp;lt;- read.csv(&amp;#39;ACS-income-data-aggregated.csv&amp;#39;)

#Filter to only 2016; aggregate incomes
df &amp;lt;- tmp%&amp;gt;%
 filter(Year == 2016) %&amp;gt;%
  group_by(Sex,Hours.work) %&amp;gt;%
  summarize(count = sum(N), avg.income = weighted.mean(avg.income, N)) %&amp;gt;%
  filter(Hours.work != &amp;quot;&amp;quot;)%&amp;gt;%
  mutate(pct = count/sum(count))

#Side by side; faceted by sex:
ggplot(data = df) + 
 geom_bar(aes(x = Hours.work, y = 100*pct, fill=Hours.work), stat=&amp;#39;identity&amp;#39;) + 
  scale_fill_brewer(palette=&amp;#39;Blues&amp;#39;) +
  guides(fill=FALSE) +
  theme_dark()+
   ggtitle(&amp;#39;Employment level by sex: Bar chart&amp;#39;) +
 facet_wrap(~Sex)+
    theme(panel.grid=element_blank()) + 
  xlab(&amp;#39;Employment level&amp;#39;) + ylab(&amp;#39;Percent&amp;#39;)+
  ylim(c(0,100))

#Side by side; faceted by employment level:
ggplot(data = df) + 
 geom_bar(aes(x = Sex, y = 100*pct, fill=Hours.work), stat=&amp;#39;identity&amp;#39;) + 
  scale_fill_brewer(palette=&amp;#39;Blues&amp;#39;) +
  guides(fill=FALSE) +
  theme_dark()+
 facet_grid(.~Hours.work)+
    theme(panel.grid=element_blank()) + 
  xlab(&amp;#39;Employment level&amp;#39;) + ylab(&amp;#39;Percent&amp;#39;)+
  ylim(c(0,100))

#Stacked:
ggplot(data = df) + 
 geom_bar(aes(x = Sex, y = 100*pct, fill=Hours.work), stat=&amp;#39;identity&amp;#39;) + 
  scale_fill_brewer(name=&amp;#39;Employment level&amp;#39;,palette=&amp;#39;Blues&amp;#39;) +
  theme_dark()+
    theme(panel.grid=element_blank()) + 
  xlab(&amp;#39;Employment level&amp;#39;) + ylab(&amp;#39;Percent&amp;#39;)+
  ylim(c(0,100))&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>Gestalt principles and income inequality</title>
      <link>http://driftlessdata.space/post/income-gestalt/</link>
      <pubDate>Tue, 12 Dec 2017 00:00:00 +0000</pubDate>
      
      <guid>http://driftlessdata.space/post/income-gestalt/</guid>
      <description>&lt;p&gt;The fall semester is over and final grades are in, which means it’s time to reflect on what just took place and how to grow from here. Today, I reflect on my third time teaching the &lt;a href=&#34;http://driftlessdata.space/courses/dsci310/home/&#34;&gt;data visualization course&lt;/a&gt;. This course has come a long way since the first time I taught it in Fall 2015, and yet there are still so many improvements to make! One of the concepts I want to greater emphasize next time I teach the course are the &lt;em&gt;Gestalt principles&lt;/em&gt;, which Gestalt psychologist Kurt Koffka summarizes as the idea that &lt;a href=&#34;https://www.interaction-design.org/literature/topics/gestalt-principles&#34;&gt;“The whole is &lt;em&gt;other&lt;/em&gt; than the sum of the parts.”&lt;/a&gt;. I like to think of the Gestalt principles as ground rules for how to create meaningful patterns out of chaos.&lt;/p&gt;
&lt;p&gt;Twain Taylor has an &lt;a href=&#34;https://www.fusioncharts.com/blog/how-to-use-the-gestalt-principles-for-visual-storytelling-podv/&#34;&gt;excellent post&lt;/a&gt; on how the Gestalt principles manifest in data visualization. He summarizes the principles in this chart:&lt;/p&gt;
&lt;div class=&#34;figure&#34;&gt;
&lt;img src=&#34;https://www.fusioncharts.com/blog/wp-content/uploads/2014/03/illustrations.jpg&#34; /&gt;

&lt;/div&gt;
&lt;p&gt;Quoting from his &lt;a href=&#34;https://www.fusioncharts.com/blog/how-to-use-the-gestalt-principles-for-visual-storytelling-podv/&#34;&gt;post&lt;/a&gt;;&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;Here is what we notice from each of the illustrations:&lt;/p&gt;
&lt;/blockquote&gt;
&lt;blockquote&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Proximity&lt;/strong&gt;: We see three rows of dots instead of four columns of dots because they are closer horizontally than vertically.&lt;br /&gt;
&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Similarity&lt;/strong&gt;: We see similar looking objects as part of the same group.&lt;br /&gt;
&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Enclosure&lt;/strong&gt;: We group the first four and and last four dots as two rows instead of eight dots.&lt;br /&gt;
&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Symmetry&lt;/strong&gt;: We see three pairs of symmetrical brackets rather than six individual brackets.&lt;br /&gt;
&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Closure&lt;/strong&gt;: We automatically close the square and circle instead of seeing three disconnected paths.&lt;br /&gt;
&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Continuity&lt;/strong&gt;: We see one continuous path instead of three arbitrary ones.&lt;br /&gt;
&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Connection&lt;/strong&gt;: We group the connected dots as belonging to the same group.&lt;br /&gt;
&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Figure &amp;amp; ground&lt;/strong&gt;: We either notice the two faces, or the vase. Whichever we notice becomes the figure, and the other the ground&lt;/li&gt;
&lt;/ul&gt;
&lt;/blockquote&gt;
&lt;p&gt;In my experience visualizing data, it seems the most pervasive principles are &lt;em&gt;proximity&lt;/em&gt;, &lt;em&gt;similarity&lt;/em&gt;, &lt;em&gt;enclosure&lt;/em&gt;, and &lt;em&gt;connection&lt;/em&gt;.&lt;/p&gt;
&lt;p&gt;I was struck by the ubiquitousness of these principles as I was reviewing my students’ final visualization projects. One &lt;a href=&#34;https://public.tableau.com/views/STEM_8/Salary?:embed=y&amp;amp;:display_count=yes&#34;&gt;very fine project in particular&lt;/a&gt; inspired me to write this post. Next time I teach the visualization course, I hope to include the following example to illustrate these principles to my students.&lt;/p&gt;
&lt;div id=&#34;illustrating-the-gestalt-principles-with-acs-income-data&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Illustrating the Gestalt principles with ACS income data&lt;/h3&gt;
&lt;p&gt;As an example data set, I settled on data over 2009-2016 from the &lt;a href=&#34;https://www.census.gov/programs-surveys/acs/&#34;&gt;American Community Survey&lt;/a&gt;, which I requested from the &lt;a href=&#34;https://usa.ipums.org/usa/index.shtml&#34;&gt;IPUMS USA&lt;/a&gt; data request system. I specifically requested incomes by year, sex, educational attainment, and field of degree. I filtered the data to only include those with a Bachelor’s degree or higher who were currently employed at the time of sampling, and created a new variable to indicate whether or not the field was a STEM field (using a combination of &lt;a href=&#34;http://mentornet.org/service/stem_fields.html&#34;&gt;this source&lt;/a&gt; and &lt;a href=&#34;http://stemdegreelist.com/&#34;&gt;this source&lt;/a&gt; to help me determine).&lt;/p&gt;
&lt;p&gt;The primary question I want to visualize is: &lt;strong&gt;&lt;em&gt;What is the inequality in average income comparing males to females?&lt;/em&gt;&lt;/strong&gt; Of course, average income depends on many other factors, including field of degree, type of degree, and year, to name just a few. We’ll focus on visualizing the gender income gap adjusting for these other factors as well.&lt;/p&gt;
&lt;p&gt;Here’s a quick look at the first six rows of the data set.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;##   Year    Sex              Educ    Field avg.income
## 1 2009 Female Bachelor&amp;#39;s degree Non-STEM   47440.41
## 2 2009 Female Bachelor&amp;#39;s degree     STEM   51423.20
## 3 2009 Female   Doctoral degree Non-STEM   77378.22
## 4 2009 Female   Doctoral degree     STEM   87257.88
## 5 2009 Female   Master&amp;#39;s degree Non-STEM   60549.57
## 6 2009 Female   Master&amp;#39;s degree     STEM   65621.16&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Notably, the data set consists of one row per year/sex/education/field category, with &lt;code&gt;avg.income&lt;/code&gt; indicating the average income for that combination.&lt;/p&gt;
&lt;p&gt;So let’s visualize! We want to investigate the gender income gap, so here’s a first go:&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;http://driftlessdata.space/post/income-gestalt_files/figure-html/unnamed-chunk-2-1.png&#34; width=&#34;288&#34; /&gt;&lt;/p&gt;
&lt;p&gt;Mostly, this is chaos! But we do see the Gestalt principle of &lt;strong&gt;&lt;em&gt;proximity&lt;/em&gt;&lt;/strong&gt; manifest itself: we perceive the incomes on the left (belonging to females) as a group, and the incomes on the right (belonging to males) as a group. Let’s incorporate &lt;strong&gt;Year&lt;/strong&gt; on the horizontal, since we are accustomed to identifying trends across time:&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;http://driftlessdata.space/post/income-gestalt_files/figure-html/unnamed-chunk-3-1.png&#34; width=&#34;384&#34; /&gt;&lt;/p&gt;
&lt;p&gt;We now see year groupings by way of the &lt;strong&gt;&lt;em&gt;proximity&lt;/em&gt;&lt;/strong&gt; principle, and sex groupings via color-coding with the &lt;strong&gt;&lt;em&gt;similarity&lt;/em&gt;&lt;/strong&gt; principle. There’s still too much chaos, however. Let’s try again:&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;http://driftlessdata.space/post/income-gestalt_files/figure-html/unnamed-chunk-4-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;The amount of chaos is reduced dramatically, all by way of implementing the &lt;strong&gt;&lt;em&gt;enclosure&lt;/em&gt;&lt;/strong&gt; principle, specifically enclosing the highest level of educational attainments together in separate panels. This particular type of enclosure is often referred to as &lt;em&gt;faceting&lt;/em&gt; in the data visualization realm. The drastic reduction in chaos, and improvement of clarity, is due to the fact that there were four educational attainment groupings. We would not have improved the clarity as much if we had, say, grouped by field of degree instead, which only has two groups:&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;http://driftlessdata.space/post/income-gestalt_files/figure-html/unnamed-chunk-5-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;Faceting by educational attainment is better, so let’s continue working with that one, now indicating field of degree:&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;http://driftlessdata.space/post/income-gestalt_files/figure-html/unnamed-chunk-6-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;The new principle is &lt;strong&gt;&lt;em&gt;connection&lt;/em&gt;&lt;/strong&gt;. Clearly, we perceive each line as an entity, representing now a Sex/Field combination (Male/STEM, for example). Another instance of &lt;strong&gt;&lt;em&gt;similarity&lt;/em&gt;&lt;/strong&gt; is in play, since the lines for STEM fields are dashed, while the lines for non-STEM fields are solid.&lt;/p&gt;
&lt;p&gt;So, here we have it, a visualization that illustrates the principles of &lt;strong&gt;&lt;em&gt;proximity&lt;/em&gt;&lt;/strong&gt;, &lt;strong&gt;&lt;em&gt;similarity&lt;/em&gt;&lt;/strong&gt;, &lt;strong&gt;&lt;em&gt;enclosure&lt;/em&gt;&lt;/strong&gt;, and &lt;strong&gt;&lt;em&gt;connection&lt;/em&gt;&lt;/strong&gt;. We’ve implemented these principles to significantly reduce chaos and improve clarity. But there’s still an issue with this visualization. Remember the intent of the visualization is to explore &lt;strong&gt;gender income inequality&lt;/strong&gt;. If we take another look at the above visualization, this is not the most obvious comparison to make. Rather, due to the &lt;strong&gt;&lt;em&gt;proximity&lt;/em&gt;&lt;/strong&gt; and &lt;strong&gt;&lt;em&gt;similarity&lt;/em&gt;&lt;/strong&gt; of the lines within each sex (they are close together, and of the same color), the comparison our brain is encouraged to make is to compare incomes of STEM to non-STEM, &lt;em&gt;within&lt;/em&gt; sex. That’s not the most important comparison! It makes most sense to compare males to females, &lt;em&gt;within&lt;/em&gt; field.&lt;/p&gt;
&lt;p&gt;This brings us to a related concept: &lt;em&gt;not all means of introducing similarity are created equal&lt;/em&gt;. When we group by similarity, we tend to first recognize similarities in &lt;em&gt;color&lt;/em&gt;, then in &lt;em&gt;shape&lt;/em&gt;. Angela Wright, a color psychologist, states that &lt;a href=&#34;http://businessadvance.com/wp-content/uploads/2015/04/white-paper-sequence-of-cognition.pdf&#34;&gt;“color is noticed by the brain before shapes or wording.”&lt;/a&gt; Thus if we want the encourage the viewer to compare the sexes, we should probably color-code by field instead, so we compare income by gender &lt;em&gt;within&lt;/em&gt; field. Here’s how that looks:&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;http://driftlessdata.space/post/income-gestalt_files/figure-html/unnamed-chunk-7-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;I’m still not convinced that this encourages the brain to first compare the sexes to each other. The &lt;strong&gt;&lt;em&gt;proximity&lt;/em&gt;&lt;/strong&gt; of the STEM and non-STEM lines is too hard to overcome! We might need to introduce another layer of &lt;strong&gt;&lt;em&gt;enclosure&lt;/em&gt;&lt;/strong&gt; (by way of faceting) to make the important comparison the most obvious:&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;http://driftlessdata.space/post/income-gestalt_files/figure-html/unnamed-chunk-8-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;details-on-data-collection-and-visualization&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Details on data collection and visualization&lt;/h3&gt;
&lt;p&gt;IPUMS stands for &lt;em&gt;Integrated Public-Use Microdata Series&lt;/em&gt;. The suite of &lt;a href=&#34;https://www.ipums.org/&#34;&gt;IPUMS tools&lt;/a&gt; is an excellent source of varied data, from health to education to international census data. I aggregated the data for this example from the microdata extract, and you can download a &lt;a href=&#34;https://www.dropbox.com/s/r729zbwjjxoboy1/ACS-stem-aggregated.csv?dl=0&#34;&gt;.csv of the aggregated data here&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;R code for creating the “final two” visualizations is below:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;library(ggplot2)
#Assuming file is in current working directory:
stemdata &amp;lt;- read.csv(&amp;quot;ACS-stem-aggregated.csv&amp;quot;)
stemdata$Educ &amp;lt;- factor(stemdata$Educ, levels = c(&amp;quot;Bachelor&amp;#39;s degree&amp;quot;,&amp;quot;Master&amp;#39;s degree&amp;quot;,&amp;quot;Doctoral degree&amp;quot;,&amp;quot;Professional degree&amp;quot;))

#Faceting by education;
#color-coding by field;
#different lines for Sex:
ggplot(data = stemdata) + 
   geom_point(aes(x = Year, y = avg.income/1000,color=Field)) +
     geom_line(aes(x = Year, y = avg.income/1000,color=Field,linetype=Sex)) +
                facet_grid(.~Educ)+
  ylab(&amp;#39;Average income (in thousand $)&amp;#39;)


#Double faceting:
ggplot(data = stemdata) + 
  #geom_point(aes(x = Year, y = avg.income/1000, shape=Sex)) +
     geom_line(aes(x = Year, y = avg.income/1000,linetype=Sex)) +
                facet_grid(Field~ Educ)+
  ylab(&amp;#39;Average income (in thousand $)&amp;#39;)&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>And the winner is...</title>
      <link>http://driftlessdata.space/post/policedatachallenge/</link>
      <pubDate>Thu, 07 Dec 2017 00:00:00 -0600</pubDate>
      
      <guid>http://driftlessdata.space/post/policedatachallenge/</guid>
      <description>&lt;p&gt;The &lt;a href=&#34;http://driftlessdata.space/courses/dsci310/midterm/&#34;&gt;midterm project for my data visualization course&lt;/a&gt; this past fall required students to submit to the &lt;a href=&#34;http://thisisstatistics.org/policedatachallenge/&#34;&gt;ASA&amp;rsquo;s Police Data Challenge&lt;/a&gt;.  The competition involved analyzing millions of 911 calls for one of three cities (Baltimore, Cincinnati, or Seattle).  I had the students investigate the Seattle data set, since it contained latitudes and longitudes of each call.&lt;/p&gt;

&lt;p&gt;Several weeks later, we received the exciting news that one of the teams won &lt;a href=&#34;http://thisisstatistics.org/police-data-challenge-congratulations-to-our-winners/&#34;&gt;&amp;ldquo;Best Overall&amp;rdquo;&lt;/a&gt; among undergraduate teams!  Congratulations to Winona State students &lt;a href=&#34;https://www.linkedin.com/in/jimmyjhickey/&#34;&gt;Jimmy Hickey&lt;/a&gt;, &lt;a href=&#34;https://www.linkedin.com/in/kapil-khanal/&#34;&gt;Kapil Khanal&lt;/a&gt;, and Luke Peacock for their excellent work.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Minne MUDAC 2017</title>
      <link>http://driftlessdata.space/post/minnemudac/</link>
      <pubDate>Fri, 10 Nov 2017 00:00:00 -0600</pubDate>
      
      <guid>http://driftlessdata.space/post/minnemudac/</guid>
      <description>&lt;p&gt;&lt;center&gt;
&lt;figure&gt;
&lt;img src=&#34;http://driftlessdata.space/img/all-teams.jpg&#34; alt=&#34;placeholder&#34; title=&#34;test&#34; height=&#34;400&#34; width=&#34;600&#34; /&gt;
 &lt;b&gt; Winona State University undergraduates made a great impression at the 2017 &lt;a href=&#34;http://minneanalytics.org/minnemudac&#34;&gt; MinneMUDAC data analytics competition &lt;/a&gt; &lt;/b&gt;
&lt;/figure&gt;
&lt;/center&gt;&lt;/p&gt;

&lt;p&gt;On November 3-4, Winona State statistics and data science students participated in the fantastic &lt;a href=&#34;http://minneanalytics.org/minnemudac/&#34;&gt;MinneMUDAC 2017&lt;/a&gt; data analytics competition.  Students worked
in teams of up to five students for one month analyzing de-identified administrative medical and pharmacy claims data provided by &lt;a href=&#34;https://www.optum.com/&#34;&gt;Optum&lt;/a&gt;.  The competition
required students to analyze complicated data on health insurance claims made by Type-II diabetics.  The event was hosted by &lt;a href=&#34;http://minneanalytics.org/&#34;&gt;MinneAnalytics&lt;/a&gt; at the Optum campus in Bloomington, Minnesota.&lt;/p&gt;

&lt;p&gt;The event began the evening of November 3. MinneAnalytics provided dinner and a professional Q&amp;amp;A panel of data scientists.  The event kicked off in earnest on Saturday, November 4.  Students gave
their 5-minute presentations to teams of judges, and  were scored on a variety of criteria ranging from analytic acumen; presentation organization; and team synergy.  Some weight
was also given by how accurately teams could predict the top-6000 most expensive Type-II diabetics for the next calendar year for a held-out target data set of patients for
which the actual insurance costs were known only to the event organizers.&lt;/p&gt;

&lt;p&gt;The top five teams from the first round went on to present to all judges in a final round.  From this final round, teams were given awards for &amp;ldquo;Best overall&amp;rdquo;; &amp;ldquo;Analytic acumen&amp;rdquo;; and
&amp;ldquo;Serendipitous discovery.&amp;rdquo;&lt;/p&gt;

&lt;p&gt;There were 22 total undergraduate teams who participated.  We were very excited that of the top five teams to proceed to the final round,
three were from Winona State!  Of these three, one won &amp;ldquo;Best overall&amp;rdquo; and another the award for &amp;ldquo;Analytic acumen.&amp;rdquo;  We were very proud of all our students
who participated.  Each one of them took time out of their busy semesters to gain fantastic professional development experience.  From real-life data analysis
of a very messy and complicated data set to presenting their results to panels of industry and academic professionals, it will be an experience that will serve them all very well.&lt;/p&gt;

&lt;p&gt;&lt;center&gt;
&lt;center&gt;
&lt;figure&gt;
&lt;img src=&#34;http://driftlessdata.space/img/best-overall.jpg&#34; alt=&#34;placeholder&#34; title=&#34;test&#34; height=&#34;400&#34; width=&#34;600&#34; /&gt;
&lt;b&gt; The &amp;ldquo;Best Overall&amp;rdquo; team at MinneMUDAC 2017, from Winona State University.
From left to right: Sam Meyer; Sam Dokkebakken; Eddie Schmitt; Austin Ellingworth; and Jack Barta &lt;/b&gt;
&lt;/figure&gt;
&lt;/center&gt;&lt;/p&gt;

&lt;p&gt;&lt;center&gt;
&lt;figure&gt;
&lt;img src=&#34;http://driftlessdata.space/img/analytic-acumen.jpg&#34; alt=&#34;placeholder&#34; title=&#34;test&#34; height=&#34;400&#34; width=&#34;600&#34; /&gt;
 &lt;b&gt; The &amp;ldquo;Analytic Acumen&amp;rdquo; award went to this team from Winona State University.
From left to right: Reagan Buske; Chris Humbert; Mariah Quam; David Stampley Jr; and McHale Dye. &lt;/b&gt;
&lt;/figure&gt;
&lt;/center&gt;&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Play Day Task</title>
      <link>http://driftlessdata.space/courses/dsci310/playday4/</link>
      <pubDate>Tue, 07 Nov 2017 00:00:00 +0000</pubDate>
      
      <guid>http://driftlessdata.space/courses/dsci310/playday4/</guid>
      <description>

&lt;p&gt;This play day is modified from a similar assignment by Jerzy Wieczorek of &lt;a href=&#34;http://civilstat.com/&#34;&gt;CivilStat.com&lt;/a&gt; specifically &lt;a href=&#34;http://civilstat.com/datavis/36721F15/Assignments/HW2_VisualPerception.pdf&#34;&gt;this one&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;Consider &lt;a href=&#34;https://www.dropbox.com/s/6g864cc4s4rc9ni/degrees.csv?dl=0&#34;&gt;data tablulated&lt;/a&gt; from the 2010 Digest of Education Statistics, &lt;a href=&#34;https://nces.ed.gov/programs/digest/d10/tables_3.asp#Ch3aSub4&#34;&gt;tables 308 to 330.&lt;/a&gt;.  The intent of this data is to answer:&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;In what fields are more women entering college?&lt;/li&gt;
&lt;li&gt;How is each field&amp;rsquo;s gender balance changing?&lt;br /&gt;&lt;/li&gt;
&lt;li&gt;Is there a difference in gender balance comparing STEM to non-STEM fields?&lt;br /&gt;&lt;/li&gt;
&lt;li&gt;How has the gender balance in STEM fields changed relative to the balance in non-STEM fields over time?&lt;br /&gt;&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;Here is &lt;a href=&#34;https://public.tableau.com/views/STEMdataAvizforstudentcritique/Dashboard1?:embed=y&amp;amp;:display_count=yes&amp;amp;publish=yes&#34;&gt;one take&lt;/a&gt;.&lt;/p&gt;

&lt;h3 id=&#34;step-1&#34;&gt;Step 1&lt;/h3&gt;

&lt;p&gt;Critique this visualization at your tables, making a list of your critiques.  &lt;strong&gt;&lt;em&gt;Be specific&lt;/em&gt;&lt;/strong&gt;, considering:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;What comparisons do you want to make, and how easy is it to make those comparisons?&lt;br /&gt;&lt;/li&gt;
&lt;li&gt;What are redesigns that would make those comparisons easier by better exploiting principles of visual perception?&lt;br /&gt;&lt;/li&gt;
&lt;li&gt;What aesthetic attributes need changing?&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Each student should submit critiques to the Play Day 4 submission folder on D2L.&lt;/p&gt;

&lt;h3 id=&#34;step-2&#34;&gt;Step 2&lt;/h3&gt;

&lt;p&gt;Create a visualization using &lt;a href=&#34;https://www.dropbox.com/s/6g864cc4s4rc9ni/degrees.csv?dl=0&#34;&gt;the data&lt;/a&gt; that improves upon the one provided, incorporating the critiques you made in Step 1.  Submit the redesign to the Play Day 4 submission folder on D2L.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Quantifying thrill</title>
      <link>http://driftlessdata.space/post/viz-worldseries-wpa/</link>
      <pubDate>Tue, 31 Oct 2017 00:00:00 -0500</pubDate>
      
      <guid>http://driftlessdata.space/post/viz-worldseries-wpa/</guid>
      <description>&lt;p&gt;Monday morning, October 30, found me groggy and sandy-eyed.  The culprit was the 5-hour and 17-minute, 10-inning thriller between the LA Dodgers and Houston Astros in Game 5 of the 2017 the night before.  Thanks to living in the Central Time Zone, I went to bed around 1am. The Astros ended up defeating the Dodgers 13-12, but the game was insane, featuring three comebacks from deficits of 3 runs or more.  By the end, I was emotionally exhausted, and I didn&amp;rsquo;t even have a stake in either team!  Lots was written about the game over at &lt;a href=&#34;http://www.fangraphs.com/&#34;&gt;Fangraphs&lt;/a&gt;, one of my favorite baseball analytics websites.&lt;/p&gt;

&lt;p&gt;One &lt;a href=&#34;https://www.fangraphs.com/blogs/game-five-was-as-weird-as-it-felt/&#34;&gt;post in particular&lt;/a&gt; by Craig Edwards caught my attention from a data visualization perspective.  It compared the game to another epic game: &lt;a href=&#34;https://www.baseball-reference.com/boxes/SLN/SLN201110270.shtml&#34;&gt;Game 6 of the 2011 World Series&lt;/a&gt;, where the St. Louis Cardinals staved off elimination by defeating the Texas Rangers 10-9 in 11 innings.  The crux of the article was a table that listed the top-20 &amp;ldquo;most exciting events&amp;rdquo; of each World Series side-by-side.  Here is a screenshot of said table:&lt;/p&gt;

&lt;p&gt;&lt;center&gt;
&lt;figure&gt;
&lt;img src=&#34;http://driftlessdata.space/img/wpa-table.JPG&#34; width=&#34;400&#34; /&gt;
&lt;/figure&gt;
&lt;/center&gt;&lt;/p&gt;

&lt;p&gt;An &amp;ldquo;exciting event&amp;rdquo; is one that yields a large swing in the win expectancy of the game, as measured by Win Probability Added, or WPA.  Read Fangraph&amp;rsquo;s &lt;a href=&#34;https://www.fangraphs.com/library/misc/wpa/&#34;&gt;excellent glossary entry on WPA&lt;/a&gt; for more detail, but essentially, the bigger the WPA of an event, the more exciting it is.&lt;/p&gt;

&lt;p&gt;The table is great, but it&amp;rsquo;s hard to see which of the two games has the &lt;em&gt;most&lt;/em&gt; exciting Top-20 events.  I wanted to visualize!  But I needed the data.  Fangraphs has play logs for every single Major League game, which lists (among other metrics) the events of the game; the win expectancy following the event; and the WPA of the event.  I needed data from the &lt;a href=&#34;https://www.fangraphs.com/plays.aspx?date=2011-10-27&amp;amp;team=Cardinals&amp;amp;dh=0&amp;amp;season=2011&#34;&gt;Game 6, 2011&lt;/a&gt; and the &lt;a href=&#34;https://www.fangraphs.com/plays.aspx?date=2017-10-29&amp;amp;team=Astros&amp;amp;dh=0&amp;amp;season=2017&#34;&gt;Game 5, 2017&lt;/a&gt; play logs.  But I needed them both in the same data source!&lt;/p&gt;

&lt;p&gt;&lt;code&gt;R&lt;/code&gt; has a great package &lt;code&gt;rvest&lt;/code&gt; that makes web-scraping (especially scraping html tables) quite easy.  Here&amp;rsquo;s the code I wrote to scrape the &lt;a href=&#34;https://www.fangraphs.com/plays.aspx?date=2011-10-27&amp;amp;team=Cardinals&amp;amp;dh=0&amp;amp;season=2011&#34;&gt;Game 6, 2011&lt;/a&gt; data; do some cleaning; and write the cleaned data into a .csv file.  I wrote very similar code to get the &lt;a href=&#34;https://www.fangraphs.com/plays.aspx?date=2017-10-29&amp;amp;team=Astros&amp;amp;dh=0&amp;amp;season=2017&#34;&gt;Game 5, 2017&lt;/a&gt; data:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;library(rvest)
library(dplyr)
#Read in the data, find the right table:
url &amp;lt;- &#39;https://www.fangraphs.com/plays.aspx?date=2011-10-27&amp;amp;team=Cardinals&amp;amp;dh=0&amp;amp;season=2011&#39;
raw &amp;lt;- read_html(url)%&amp;gt;%
       html_table(fill=TRUE)
mytable &amp;lt;- raw[[9]][,1:12]

#Use dplyr to clean it up. By code row:
  #Create absolute value of WPA
  #Create new column to indicate the game
  #Remove the &amp;quot;%&amp;quot; from the win expectancy, create Event number
  #Arrange in descending order by WPA
  #Create rank column
cleantable &amp;lt;- mytable %&amp;gt;%
  mutate(WPA_abs = abs(WPA)) %&amp;gt;%                                            
  mutate(Game = rep(&#39;Game 6, 2011&#39;,nrow(mytable))) %&amp;gt;%                    
  mutate(WE = as.numeric(gsub(&#39;%&#39;,&#39;&#39;,WE)), Event = 1:nrow(mytable)) %&amp;gt;%      
  arrange(-WPA_abs) %&amp;gt;%                                                     
  mutate(WPA_Rank = 1:nrow(mytable))                                          

#Write cleaned data to csv file
write.csv(cleantable,file=&#39;WPA_Game6_2011_all.csv&#39;,row.names=FALSE)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Then on to visualizing!  Using Tableau, I created a win-expectancy graph for each of the games.  The red dots indicate &amp;ldquo;exciting events&amp;rdquo;; events with WPA of 15% or more:&lt;/p&gt;

&lt;p&gt;&lt;center&gt;
&lt;iframe src=&#34;https://public.tableau.com/views/WPA_WS_blog/tracker-dash?:embed=y?:showVizHome=no&#34;
 width=&#34;755&#34; height=&#34;392&#34;&gt;&lt;/iframe&gt;
&lt;/center&gt;&lt;/p&gt;

&lt;p&gt;Clearly, both games were crazy, with wild swings in win expectancy!  If you count up the red dots, Game 6 in 2011 had 8 &amp;ldquo;exciting events&amp;rdquo; while Game 5 in 2017 had 10 &amp;ldquo;exciting events.&amp;rdquo;  15% is quite an arbitrary threshold for &amp;ldquo;exciting&amp;rdquo; however; different thresholds would likely change the comparison.  Comparing total WPA flips the story: the total WPA of 7.2 in Game 6, 2011 was larger than the total WPA of 6.2 in Game 5, 2017.&lt;/p&gt;

&lt;p&gt;My primary interest, however, was to compare the top-20 most exciting events of both games in a clearer visual manner, respecting principles of human perception:&lt;/p&gt;

&lt;iframe src=&#34;https://public.tableau.com/views/WPA_WS_blog/Top-20?:embed=y?:showVizHome=no&#34;
 width=&#34;655&#34; height=&#34;495&#34;&gt;&lt;/iframe&gt;

&lt;p&gt;From this graph, we can see the four points on the right that lie below the reference line.  These indicate that the top four most exciting events in Game 6, 2011 were &lt;em&gt;more exciting&lt;/em&gt; than the top four most exciting events from Game 5, 2017.  On the other hand, the top 5-10 most exciting events in Game 5, 2017 lie above the reference line, indicating they were more exciting than the events with WPA ranked 5-10 in Game 6, 2011.  The rest of the events ranked 11-20 in WPA go back to lying below the line.&lt;/p&gt;

&lt;p&gt;So, it does appear that Game 6, 2011 was truly a more thrilling game than Game 5, 2017!   The total WPA of Game 6, 2011 was greater than the total WPA in Game 5, 2017, and of the top-20 &amp;ldquo;most exciting&amp;rdquo; events, they tended to be &lt;em&gt;more exciting&lt;/em&gt; in 2011. Oh well, Game 5, 2017 was still worth losing a few hours of sleep!  I think&amp;hellip;.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Final project</title>
      <link>http://driftlessdata.space/courses/dsci310/final/</link>
      <pubDate>Mon, 30 Oct 2017 00:00:00 +0000</pubDate>
      
      <guid>http://driftlessdata.space/courses/dsci310/final/</guid>
      <description>

&lt;h3 id=&#34;description&#34;&gt;Description&lt;/h3&gt;

&lt;p&gt;For your final project, you are to find your own data source(s) and create a &amp;ldquo;visual story&amp;rdquo; visualizing insights from the data.  Your visual story should consist of at least 1 but no more than 3 dashboards visualizing these data.  This project is &amp;ldquo;tool agnostic&amp;rdquo;: you may create your visualizations using Tableau, or R, or any other visualization software.  &lt;strong&gt;&lt;em&gt;The only requirement is that whatever software you use produces a final dashboard product that is ready-to-publish on the Internet.&lt;/em&gt;&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;If using R, check out &lt;a href=&#34;http://rmarkdown.rstudio.com/flexdashboard/index.html&#34;&gt;flexdashboards&lt;/a&gt;.  This is an easy template for creating dashboards using R Markdown.  Flexdashboards allow you to create ready-to-publish html page.&lt;/p&gt;

&lt;p&gt;Each visual story should include one (1) &amp;ldquo;introductory&amp;rdquo; dashboard.  This should include text/images explaining:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;Data source;&lt;/li&gt;
&lt;li&gt;any prerequisite data cleaning;&lt;/li&gt;
&lt;li&gt;questions to be asked of the data and answered in subsequent visualizations.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;This &amp;ldquo;introductory&amp;rdquo; dashboard &lt;strong&gt;&lt;em&gt;is in addition to&lt;/em&gt;&lt;/strong&gt; your 1-3 dashboards with actual data visualizations.&lt;/p&gt;

&lt;p&gt;All students will give a 10-12 minute presentation to the class showcasing their visual story.&lt;/p&gt;

&lt;h3 id=&#34;timeline&#34;&gt;Timeline&lt;/h3&gt;

&lt;ol&gt;
&lt;li&gt;&lt;strong&gt;Monday, October 30&lt;/strong&gt;: Description of data source(s) (including link(s)) with at least three (3) draft questions you will ask of the data source due to D2L.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Friday, November 17&lt;/strong&gt;: Oral presentations of visual stories begin.  All students must have final dashboards uploaded to D2L by this date.  We will use the final exam slot on Monday, December 4 from 3:30-5:30 pm to complete presentations.&lt;/li&gt;
&lt;/ol&gt;

&lt;h3 id=&#34;grading&#34;&gt;Grading&lt;/h3&gt;

&lt;p&gt;Your final grade will consist of the following:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://www.dropbox.com/s/6seigmxr2f3pef6/Fall%202017%20Rubric.docx?dl=0&#34;&gt;Visual story rubric (75%)&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://www.dropbox.com/s/htstmyy49j2esu3/Oral%20Rubric.docx?dl=0&#34;&gt;Oral rubric (25%)&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&#34;presentation-order&#34;&gt;Presentation order&lt;/h3&gt;

&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;Order&lt;/th&gt;
&lt;th&gt;Student&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;

&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;1&lt;/td&gt;
&lt;td&gt;&lt;a href=&#34;https://public.tableau.com/profile/kapil.khanal#!/vizhome/WinonaAreaPublicSchoolsDataCleaningandVisualization/SecondDashboard?publish=yes&#34;&gt;Khanal, Kapil&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;2&lt;/td&gt;
&lt;td&gt;&lt;a href=&#34;https://public.tableau.com/profile/mariah7628#!/vizhome/310Final/Dashboard3?publish=yes&#34;&gt;Quam, Mariah S&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;3&lt;/td&gt;
&lt;td&gt;&lt;a href=&#34;https://public.tableau.com/profile/akif5393#!/vizhome/FinalProjectDraft_1/EnrollmentandExpenditureAmongdifferentfacilities?publish=yes&#34;&gt;Khan, Akif A&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;4&lt;/td&gt;
&lt;td&gt;&lt;a href=&#34;https://public.tableau.com/profile/mchale.dye#!/vizhome/FINALPROJECTIPUMMENTALHEALTH/Insights?publish=yes&#34;&gt;Dye, McHale T&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;5&lt;/td&gt;
&lt;td&gt;&lt;a href=&#34;https://public.tableau.com/profile/yulun.xu#!/vizhome/final_144/Introduction?publish=yes&#34;&gt;Xu, Yulun&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;6&lt;/td&gt;
&lt;td&gt;&lt;a href=&#34;https://public.tableau.com/profile/ross.krueger#!/vizhome/DSCI310FinalProjectAnAnalysisofDrugDeathsintheUS/IntroSheet&#34;&gt;Krueger, Ross L&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;7&lt;/td&gt;
&lt;td&gt;&lt;a href=&#34;https://public.tableau.com/profile/jack.barta#!/&#34;&gt;Barta, Jack A&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;8&lt;/td&gt;
&lt;td&gt;&lt;a href=&#34;https://public.tableau.com/profile/austin.ellingworth1102#!/vizhome/FINALPROJECTGOOD/Intro?publish=yes&#34;&gt;Ellingworth, Austin J&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;9&lt;/td&gt;
&lt;td&gt;&lt;a href=&#34;https://public.tableau.com/profile/catherine.nead#!/vizhome/RioOlympicGames2016/Introduction&#34;&gt;Nead, Catherine M&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;10&lt;/td&gt;
&lt;td&gt;&lt;a href=&#34;https://public.tableau.com/profile/tom.gathje#!/&#34;&gt;Gathje, Thomas J&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;11&lt;/td&gt;
&lt;td&gt;&lt;a href=&#34;https://public.tableau.com/views/DataScienceFinal/Intro?:embed=y&amp;amp;:display_count=yes&amp;amp;publish=yes&#34;&gt;Willkom, Lauren M&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;12&lt;/td&gt;
&lt;td&gt;&lt;a href=&#34;https://public.tableau.com/profile/matthew2057#!/vizhome/DSci310FinalProject/IntroDash?publish=yes&#34;&gt;Ladin, Matthew F&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;13&lt;/td&gt;
&lt;td&gt;&lt;a href=&#34;https://public.tableau.com/profile/stacey.miertschin#!/vizhome/Africa_Final/Intro&#34;&gt;Miertschin, Stacey L&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;14&lt;/td&gt;
&lt;td&gt;&lt;a href=&#34;https://public.tableau.com/profile/bradley.erickson#!/&#34;&gt;Erickson, Bradley W&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;15&lt;/td&gt;
&lt;td&gt;Smith, Nathan R&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;16&lt;/td&gt;
&lt;td&gt;&lt;a href=&#34;https://public.tableau.com/profile/adam.clemens#!/&#34;&gt;Clemens, Adam J&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;17&lt;/td&gt;
&lt;td&gt;&lt;a href=&#34;https://public.tableau.com/profile/waheed.khan#!/vizhome/ForPublic/VisualizationofAccidentsinMinnesota?publish=yes&#34;&gt;Khan, Waheed&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;18&lt;/td&gt;
&lt;td&gt;&lt;a href=&#34;https://public.tableau.com/profile/sam.dokkebakken#!/vizhome/GoldenStateWarriors/Dashboard4&#34;&gt;Dokkebakken, Sam C&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;19&lt;/td&gt;
&lt;td&gt;&lt;a href=&#34;https://public.tableau.com/views/DSCI310-FinalProject/Introductiontodata?:embed=y&amp;amp;:display_count=yes&amp;amp;publish=yes&#34;&gt;Stampley, David L&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;20&lt;/td&gt;
&lt;td&gt;&lt;a href=&#34;https://public.tableau.com/profile/max.oelerking#!/vizhome/BaseballDataStory_0/Intro&#34;&gt;Oelerking, Maxwell S&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;21&lt;/td&gt;
&lt;td&gt;&lt;a href=&#34;https://public.tableau.com/profile/jimmy.hickey#!/vizhome/UsingDatatoBetterUnderstandMentalHealth/Title&#34;&gt;Hickey, James J&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;22&lt;/td&gt;
&lt;td&gt;&lt;a href=&#34;https://public.tableau.com/profile/samantha.meyer#!/&#34;&gt;Meyer, Samantha&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;23&lt;/td&gt;
&lt;td&gt;&lt;a href=&#34;https://public.tableau.com/profile/reagan.buske#!/&#34;&gt;Buske, Reagan N&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;24&lt;/td&gt;
&lt;td&gt;&lt;a href=&#34;https://public.tableau.com/profile/paul.boelter#!/vizhome/NBA14-17Statisitcs/IntroductionDashboard&#34;&gt;Boelter, Paul G&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;25&lt;/td&gt;
&lt;td&gt;&lt;a href=&#34;https://public.tableau.com/profile/salman.quraishi#!/vizhome/DSCI310FinalProject/IntroductoryDashboard&#34;&gt;Quraishi, Salman M&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;26&lt;/td&gt;
&lt;td&gt;&lt;a href=&#34;https://public.tableau.com/profile/william.diedrick#!/&#34;&gt;Diedrick, William J&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;27&lt;/td&gt;
&lt;td&gt;Nguyen, Linh H&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;28&lt;/td&gt;
&lt;td&gt;&lt;a href=&#34;https://public.tableau.com/profile/fengrui.xue#!/vizhome/310my/Introduction&#34;&gt;Xue, Fengrui&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;

&lt;h3 id=&#34;example-data-sources&#34;&gt;Example data sources&lt;/h3&gt;

&lt;p&gt;Winona Area Public Schools:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://drive.google.com/open?id=0BzinIRj-gi7tYm5JWmxUdFBVYzQ&#34;&gt;Google folder with questions and data&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Government:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;Data.gov&lt;/li&gt;
&lt;li&gt;Census.gov&lt;/li&gt;
&lt;li&gt;BJS.gov (Bureau of Justice Statistics)&lt;/li&gt;
&lt;li&gt;noaa.gov&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Education:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://collegescorecard.ed.gov/data/&#34;&gt;https://collegescorecard.ed.gov/data/&lt;/a&gt;&lt;br /&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;http://www.data.gov/education/&#34;&gt;http://www.data.gov/education/&lt;/a&gt;&lt;br /&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Sports:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;http://community.amstat.org/sis/sportsdataresources&#34;&gt;http://community.amstat.org/sis/sportsdataresources&lt;/a&gt; for a list of data sources by sport&lt;br /&gt;&lt;/li&gt;
&lt;li&gt;Fangraphs.com&lt;br /&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Misc:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;http://www.start.umd.edu/gtd/&#34;&gt;Global terrorism database&lt;/a&gt;&lt;br /&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;http://www.acleddata.com/&#34;&gt;ACLED (Armed Conflict Location &amp;amp; Event Data Project)&lt;/a&gt;&lt;br /&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;http://data.worldbank.org/&#34;&gt;World Bank (economic development)&lt;/a&gt;&lt;br /&gt;&lt;/li&gt;
&lt;li&gt;Twitter API (see the twittR R package)&lt;br /&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://www.ipums.org/&#34;&gt;Integrated public-use microdata series (IPUMS)&lt;/a&gt;, including:

&lt;ul&gt;
&lt;li&gt;IPUMS USA (U.S. Census data)&lt;/li&gt;
&lt;li&gt;Demographic and Health Surveys&lt;/li&gt;
&lt;li&gt;National Health Interview Survey&lt;/li&gt;
&lt;li&gt;Higher education&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://www.kaggle.com/&#34;&gt;Kaggle&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://data.world/&#34;&gt;Data world&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;See This Blog: 30 places to find open data on the web for some ideas &lt;a href=&#34;http://blog.visual.ly/data-sources/&#34;&gt;http://blog.visual.ly/data-sources/&lt;/a&gt;.  Some sources above are mentioned in this blog.&lt;/p&gt;

&lt;p&gt;You are, of course, free to use other data sources than those mentioned above, or to scrape data using &lt;code&gt;rvest&lt;/code&gt; or some other tool.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>R Homework 3</title>
      <link>http://driftlessdata.space/courses/stat450/r_hw3/</link>
      <pubDate>Fri, 20 Oct 2017 00:00:00 +0000</pubDate>
      
      <guid>http://driftlessdata.space/courses/stat450/r_hw3/</guid>
      <description>&lt;p&gt;&lt;strong&gt;Due Wednesday, 11/8 by 11:59pm. Prepare your submission with R Markdown. Submit fully-knitted Word doc or pdf to D2L by due date. You are encouraged to use this .Rmd file as your starting point for your submission.&lt;/strong&gt;&lt;/p&gt;
&lt;ol style=&#34;list-style-type: decimal&#34;&gt;
&lt;li&gt;In Math-Stat, all of the pmfs/pdfs we have discussed are truly &lt;em&gt;models&lt;/em&gt;. This means they are proposed mathematical frameworks for explaining behavior of actual data. We consier one proposed model for some actual data in this problem. Suppose the type of breast cancer cells (malignant or benign) follow a Bernoulli distribution. Specifically, with &lt;span class=&#34;math inline&#34;&gt;\(X =1\)&lt;/span&gt; if the cell is malignant and &lt;span class=&#34;math inline&#34;&gt;\(X = 0\)&lt;/span&gt; if the cell is benign:&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[P(X = x)= 0.4^x 0.6^{1-x}.\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;Suppose that the radius of the cell in microns, &lt;span class=&#34;math inline&#34;&gt;\(Y\)&lt;/span&gt;, depends on &lt;span class=&#34;math inline&#34;&gt;\(X\)&lt;/span&gt; and can be well-modeled with the following conditional pdf:&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[ f(y|x) = \frac{1}{\sqrt{2\pi (3.2+7.1x)}}e^{-\frac{1}{2}\frac{(y- (12 +5x))^2}{3.2+7.1x}}; -\infty &amp;lt; y &amp;lt; \infty
\]&lt;/span&gt;&lt;/p&gt;
&lt;ol style=&#34;list-style-type: upper-alpha&#34;&gt;
&lt;li&gt;&lt;p&gt;Find &lt;span class=&#34;math inline&#34;&gt;\(\mu_Y = E(Y)\)&lt;/span&gt;.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Find &lt;span class=&#34;math inline&#34;&gt;\(\sigma^2_Y = Var(Y)\)&lt;/span&gt;.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;The data set BreastCancerSample.csv contains data on 569 cells. Plot bar graphs of &lt;span class=&#34;math inline&#34;&gt;\(X\)&lt;/span&gt;, and histograms of &lt;span class=&#34;math inline&#34;&gt;\(Y\)&lt;/span&gt; for each &lt;span class=&#34;math inline&#34;&gt;\(X\)&lt;/span&gt;. Does the proposed model appear reasonable?&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Find &lt;span class=&#34;math inline&#34;&gt;\(\hat\mu_Y = \hat E(Y)\)&lt;/span&gt; and &lt;span class=&#34;math inline&#34;&gt;\(\hat\sigma^2_Y = \widehat{Var}(Y)\)&lt;/span&gt;, the empirical (i.e., observed) mean and variance of the cell radii. Verify that they well-approximate the theoretical quantitities.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Now use the data to fill out the following table:&lt;/p&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr class=&#34;header&#34;&gt;
&lt;th&gt;x&lt;/th&gt;
&lt;th&gt;&lt;span class=&#34;math inline&#34;&gt;\(\hat p(x)\)&lt;/span&gt;&lt;/th&gt;
&lt;th&gt;&lt;span class=&#34;math inline&#34;&gt;\(\hat E(Y\mid X)\)&lt;/span&gt;&lt;/th&gt;
&lt;th&gt;&lt;span class=&#34;math inline&#34;&gt;\(\widehat{Var}(Y\mid X)\)&lt;/span&gt;&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td&gt;0&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td&gt;1&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;Use the quantities in this table to find &lt;span class=&#34;math inline&#34;&gt;\(\hat \mu_Y\)&lt;/span&gt; and &lt;span class=&#34;math inline&#34;&gt;\(\hat\sigma^2_Y\)&lt;/span&gt;. Verify that they match your answers to part D.&lt;/p&gt;
&lt;ol start=&#34;2&#34; style=&#34;list-style-type: decimal&#34;&gt;
&lt;li&gt;As discussed in class, if &lt;span class=&#34;math inline&#34;&gt;\((X,Y)\)&lt;/span&gt; follow a bivariate normal distribution then:&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[ E(Y|X) = \mu_Y + \rho \frac{\sigma_Y}{\sigma_X} (X-\mu_X)\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[Var(Y|X) = \sigma^2_Y( 1-\rho^2)\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;This implies that under bivariate normality, the conditional mean of &lt;span class=&#34;math inline&#34;&gt;\(Y\)&lt;/span&gt; given &lt;span class=&#34;math inline&#34;&gt;\(X\)&lt;/span&gt; is linear, and the form of the intercept and slope defining the linear relationship are explicitly determined by the means, variances, and correlation that parameterize the bivariate normal. In this problem we study this further.&lt;/p&gt;
&lt;p&gt;Consider the following combinations of parameterizations, for &lt;span class=&#34;math inline&#34;&gt;\(\mu_Y = \mu_X = 10\)&lt;/span&gt; and &lt;span class=&#34;math inline&#34;&gt;\(\sigma_X = 2\)&lt;/span&gt;:&lt;/p&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr class=&#34;header&#34;&gt;
&lt;th&gt;&lt;span class=&#34;math inline&#34;&gt;\(\rho\)&lt;/span&gt;&lt;/th&gt;
&lt;th&gt;&lt;span class=&#34;math inline&#34;&gt;\(\sigma_Y/\sigma_X\)&lt;/span&gt;&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td&gt;0.1&lt;/td&gt;
&lt;td&gt;0.5&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td&gt;0.5&lt;/td&gt;
&lt;td&gt;0.5&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td&gt;0.8&lt;/td&gt;
&lt;td&gt;0.5&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td&gt;0.1&lt;/td&gt;
&lt;td&gt;1&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td&gt;0.5&lt;/td&gt;
&lt;td&gt;1&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td&gt;0.8&lt;/td&gt;
&lt;td&gt;1&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td&gt;0.1&lt;/td&gt;
&lt;td&gt;2&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td&gt;0.5&lt;/td&gt;
&lt;td&gt;2&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td&gt;0.8&lt;/td&gt;
&lt;td&gt;2&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;Using the function &lt;code&gt;mvrnorm()&lt;/code&gt; from the &lt;code&gt;MASS&lt;/code&gt; package, simulate 100 &lt;span class=&#34;math inline&#34;&gt;\((X,Y)\)&lt;/span&gt; pairs for each row of the table above.&lt;/p&gt;
&lt;ol style=&#34;list-style-type: upper-alpha&#34;&gt;
&lt;li&gt;&lt;p&gt;Plot the 9 data sets, including the best-fit linear regression line (use &lt;code&gt;geom_smooth(method=&#39;lm&#39;)&lt;/code&gt; if using &lt;code&gt;ggplot&lt;/code&gt;).&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;By describing the scatterplots, briefly explain how the combinations of &lt;span class=&#34;math inline&#34;&gt;\(\rho\)&lt;/span&gt; and &lt;span class=&#34;math inline&#34;&gt;\(\sigma_Y/\sigma_X\)&lt;/span&gt; affect &lt;span class=&#34;math inline&#34;&gt;\(\widehat{Var}(Y|X)\)&lt;/span&gt;.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Fill out the table below, indicating the theoretical quantities of the regression coefficients, as well as the estimated coefficients from using &lt;code&gt;lm()&lt;/code&gt; on each of the 9 simulated data sets.&lt;/p&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr class=&#34;header&#34;&gt;
&lt;th&gt;&lt;span class=&#34;math inline&#34;&gt;\(\rho\)&lt;/span&gt;&lt;/th&gt;
&lt;th&gt;&lt;span class=&#34;math inline&#34;&gt;\(\sigma_Y/\sigma_X\)&lt;/span&gt;&lt;/th&gt;
&lt;th&gt;&lt;span class=&#34;math inline&#34;&gt;\(\beta_0\)&lt;/span&gt;&lt;/th&gt;
&lt;th&gt;&lt;span class=&#34;math inline&#34;&gt;\(\beta_1\)&lt;/span&gt;&lt;/th&gt;
&lt;th&gt;&lt;span class=&#34;math inline&#34;&gt;\(\hat\beta_0\)&lt;/span&gt;&lt;/th&gt;
&lt;th&gt;&lt;span class=&#34;math inline&#34;&gt;\(\hat\beta_1\)&lt;/span&gt;&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td&gt;0.1&lt;/td&gt;
&lt;td&gt;0.5&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td&gt;0.5&lt;/td&gt;
&lt;td&gt;0.5&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td&gt;0.8&lt;/td&gt;
&lt;td&gt;0.5&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td&gt;0.1&lt;/td&gt;
&lt;td&gt;1&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td&gt;0.5&lt;/td&gt;
&lt;td&gt;1&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td&gt;0.8&lt;/td&gt;
&lt;td&gt;1&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td&gt;0.1&lt;/td&gt;
&lt;td&gt;2&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td&gt;0.5&lt;/td&gt;
&lt;td&gt;2&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td&gt;0.8&lt;/td&gt;
&lt;td&gt;2&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
</description>
    </item>
    
    <item>
      <title>Play Day Task</title>
      <link>http://driftlessdata.space/courses/dsci310/playday3/</link>
      <pubDate>Mon, 16 Oct 2017 00:00:00 +0000</pubDate>
      
      <guid>http://driftlessdata.space/courses/dsci310/playday3/</guid>
      <description>&lt;p&gt;Consider the following data on &lt;a href=&#34;https://www.dropbox.com/s/f8t1p37kkueizom/migration.csv?dl=0&#34;&gt;World Migration&lt;/a&gt; from the United Nations, Department of Economic and Social Affairs, Population Division, Trends in International Migrant Stock.&lt;/p&gt;

&lt;p&gt;Questions to be answered visually (no restrictions!):&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;Which countries and regions have the most people leaving?  Where do they go?&lt;/li&gt;
&lt;li&gt;Which countries and regions have the most people entering?  Where do they come from?&lt;/li&gt;
&lt;/ul&gt;
</description>
    </item>
    
    <item>
      <title>Introduction to data visualization in R using ggplot2</title>
      <link>http://driftlessdata.space/courses/dsci310/intro_to_ggplot2/</link>
      <pubDate>Mon, 09 Oct 2017 00:00:00 +0000</pubDate>
      
      <guid>http://driftlessdata.space/courses/dsci310/intro_to_ggplot2/</guid>
      <description>&lt;div id=&#34;overview&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Overview&lt;/h2&gt;
&lt;div id=&#34;basic-grammar&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Basic grammar&lt;/h3&gt;
&lt;p&gt;Hadley’s Grammar of Graphics is outlined in detail in &lt;a href=&#34;http://vita.had.co.nz/papers/layered-grammar.pdf&#34;&gt;this article&lt;/a&gt;. Here, he illustrates his principles using a small data set similar to the following:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;df &amp;lt;- data.frame(A = c(2,1,4,9),
                 B  = c(4,1,15,80),
                 C = c(1,2,3,4),
                 D = c(&amp;#39;far&amp;#39;,&amp;#39;far&amp;#39;,&amp;#39;near&amp;#39;,&amp;#39;near&amp;#39;))
head(df)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##   A  B C    D
## 1 2  4 1  far
## 2 1  1 2  far
## 3 4 15 3 near
## 4 9 80 4 near&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;To visualize any data set using the Grammar of Graphics, it helps to understand the 3 components of which any graph is comprised:&lt;/p&gt;
&lt;ol style=&#34;list-style-type: decimal&#34;&gt;
&lt;li&gt;Geoms&lt;/li&gt;
&lt;li&gt;Scales&lt;/li&gt;
&lt;li&gt;Data columns&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;&lt;strong&gt;Geoms&lt;/strong&gt; are the visual entities that we see on a graph. In the image below, we see three examples of geoms: a circular &lt;strong&gt;&lt;em&gt;point&lt;/em&gt;&lt;/strong&gt;, a &lt;strong&gt;&lt;em&gt;bar&lt;/em&gt;&lt;/strong&gt;, and a &lt;strong&gt;&lt;em&gt;line&lt;/em&gt;&lt;/strong&gt;:&lt;/p&gt;
&lt;div class=&#34;figure&#34;&gt;
&lt;img src=&#34;img/geoms.PNG&#34; /&gt;

&lt;/div&gt;
&lt;p&gt;&lt;strong&gt;Scales&lt;/strong&gt; control how the &lt;strong&gt;data columns&lt;/strong&gt; map to the aesthetic attributes of the geoms. For example, is the point geom &lt;em&gt;yellow&lt;/em&gt; or &lt;em&gt;blue&lt;/em&gt;? Is it &lt;em&gt;large&lt;/em&gt; or &lt;em&gt;small&lt;/em&gt;? Is it &lt;em&gt;high&lt;/em&gt; or &lt;em&gt;low&lt;/em&gt;? &lt;em&gt;Left&lt;/em&gt; or &lt;em&gt;right&lt;/em&gt;? These aesthetic attributes are respectively controlled by the &lt;strong&gt;color&lt;/strong&gt;, &lt;strong&gt;size&lt;/strong&gt;, &lt;strong&gt;y&lt;/strong&gt;, and &lt;strong&gt;x&lt;/strong&gt; scales:&lt;/p&gt;
&lt;div class=&#34;figure&#34;&gt;
&lt;img src=&#34;img/scales.PNG&#34; /&gt;

&lt;/div&gt;
&lt;p&gt;Additional scales in &lt;code&gt;ggplot2&lt;/code&gt; are:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;shape&lt;/strong&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;linetype&lt;/strong&gt; (for the line geom)&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;fill&lt;/strong&gt; (for the bar and point geoms)&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Any plot created with &lt;code&gt;ggplot2&lt;/code&gt; requires these ingredients. To create a plot, one must specify the desired geom; which data variables are to be aesthetically mapped to the geom; and the scales to use to control the mapping. The skeleton of any &lt;code&gt;ggplot2&lt;/code&gt; command is as follows; parts in italics are to be replaced with specific data variable names, geoms, and scales:&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;ggplot(data = &lt;em&gt;nameofdata&lt;/em&gt;) + geom_&lt;em&gt;nameofgeom&lt;/em&gt;(aes(&lt;em&gt;scale1&lt;/em&gt; = &lt;em&gt;variable1&lt;/em&gt;, &lt;em&gt;scale2&lt;/em&gt; = &lt;em&gt;variable2&lt;/em&gt;))&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;At a minimum, most geoms require the &lt;code&gt;x&lt;/code&gt; scale.&lt;/p&gt;
&lt;p&gt;Begin by loading the package (installing first if never done before):&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;library(ggplot2)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Let’s begin by mapping &lt;code&gt;A&lt;/code&gt; and &lt;code&gt;B&lt;/code&gt; to the &lt;code&gt;point&lt;/code&gt; geom on a Cartesian plane. Note in &lt;code&gt;?geom_point&lt;/code&gt; that two scales are required for aesthetic mappings to point geoms:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;ggplot(data = df) + geom_point(aes(x = A,y=B))&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;http://driftlessdata.space/courses/dsci310/Intro_to_ggplot2_files/figure-html/unnamed-chunk-3-1.png&#34; width=&#34;384&#34; style=&#34;display: block; margin: auto;&#34; /&gt;&lt;/p&gt;
&lt;p&gt;We can employ other scales outside of aesthetic mappings. For example, if we want to change the aesthetic mapping of the above scatterplot by changing the &lt;strong&gt;shape&lt;/strong&gt;, &lt;strong&gt;color&lt;/strong&gt;, and &lt;strong&gt;size&lt;/strong&gt; scale, we can do so with the following:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;ggplot(data = df) + geom_point(aes(x = A,y=B), shape = 17,color=&amp;#39;red&amp;#39;,size=4)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;http://driftlessdata.space/courses/dsci310/Intro_to_ggplot2_files/figure-html/unnamed-chunk-4-1.png&#34; width=&#34;384&#34; style=&#34;display: block; margin: auto;&#34; /&gt;&lt;/p&gt;
&lt;p&gt;Notice in the above code that the scales that are not controlling aesthetic data mappings are &lt;em&gt;outside&lt;/em&gt; the &lt;code&gt;aes()&lt;/code&gt; command.&lt;/p&gt;
&lt;p&gt;As an aside, looking at the &lt;code&gt;?shape&lt;/code&gt; help file, we can find code to see all possible shapes:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;df2 &amp;lt;- data.frame(x = 1:5 , y = 1:25, z = 1:25)
s &amp;lt;- ggplot(df2, aes(x = x, y = y))
s + geom_point(aes(shape = z), size = 4) + scale_shape_identity()&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;http://driftlessdata.space/courses/dsci310/Intro_to_ggplot2_files/figure-html/unnamed-chunk-5-1.png&#34; width=&#34;384&#34; style=&#34;display: block; margin: auto;&#34; /&gt;&lt;/p&gt;
&lt;p&gt;Now suppose we want to aesthetically map other variables using the &lt;strong&gt;shape&lt;/strong&gt;, &lt;strong&gt;color&lt;/strong&gt;, and &lt;strong&gt;size&lt;/strong&gt; scales. We must now put these specifications inside the &lt;code&gt;aes()&lt;/code&gt; command and specify the variables we wish to map. Consider the following code, and note the different looks, error messages and warnings that appear when attempting to apply aesthetic mappings using various scales depending on the data type. In &lt;code&gt;ggplot&lt;/code&gt;-speak, “continuous” refers to quantitative data in general; while “discrete” refers to categorical data:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;#Mapping continuous C with size:
ggplot(data = df) + geom_point(aes(x = A,y=B, size = C))
#Mapping continuous C with size and color:
ggplot(data = df) + geom_point(aes(x = A,y=B, size = C, color = C))
#Mapping continuous C with shape (we know we shouldn&amp;#39;t do this!):
ggplot(data = df) + geom_point(aes(x = A,y=B, shape = C))&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;http://driftlessdata.space/courses/dsci310/Intro_to_ggplot2_files/figure-html/unnamed-chunk-7-1.png&#34; width=&#34;432&#34; /&gt;&lt;img src=&#34;http://driftlessdata.space/courses/dsci310/Intro_to_ggplot2_files/figure-html/unnamed-chunk-7-2.png&#34; width=&#34;432&#34; /&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;YOUR TURN&lt;/strong&gt;: See if you can re-create these plots:&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;http://driftlessdata.space/courses/dsci310/Intro_to_ggplot2_files/figure-html/unnamed-chunk-8-1.png&#34; width=&#34;432&#34; /&gt;&lt;img src=&#34;http://driftlessdata.space/courses/dsci310/Intro_to_ggplot2_files/figure-html/unnamed-chunk-8-2.png&#34; width=&#34;432&#34; /&gt;&lt;img src=&#34;http://driftlessdata.space/courses/dsci310/Intro_to_ggplot2_files/figure-html/unnamed-chunk-8-3.png&#34; width=&#34;432&#34; /&gt;&lt;img src=&#34;http://driftlessdata.space/courses/dsci310/Intro_to_ggplot2_files/figure-html/unnamed-chunk-8-4.png&#34; width=&#34;432&#34; /&gt;&lt;/p&gt;
&lt;p&gt;Note some interesting concepts illustrated here:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;em&gt;Continuous&lt;/em&gt; variables should be mapped using &lt;strong&gt;size&lt;/strong&gt; or &lt;strong&gt;color&lt;/strong&gt; scales; these are the scales/EPTs that can encode quantity.&lt;/li&gt;
&lt;li&gt;&lt;em&gt;Discrete&lt;/em&gt; variables should be mapped with &lt;strong&gt;shape&lt;/strong&gt; or &lt;strong&gt;color&lt;/strong&gt; scales; these are the scales/EPTs that are best used for indicating “categories.”&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;div id=&#34;layers&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Layers&lt;/h3&gt;
&lt;p&gt;A very important aspect of the &lt;code&gt;ggplot2&lt;/code&gt; package is the idea of &lt;em&gt;layers&lt;/em&gt;. Aesthetic mappings to different geoms can take place simply by specifying additional mappings with a &lt;code&gt;+&lt;/code&gt; sign. For example, suppose we want to create the above scatterplots with points &lt;em&gt;and&lt;/em&gt; lines. This requires two aesthetic mappings: one from the data to the points geom, and one from the data to the lines geom. We can see this in what follows. Note that because both &lt;code&gt;geom_point()&lt;/code&gt; and &lt;code&gt;geom_line()&lt;/code&gt; rely on the same aesthetic mapping, we could simplify the code by specifiying the appropriate mapping in the initial &lt;code&gt;ggplot()&lt;/code&gt; command. The following two lines of code are equivalent:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;ggplot(data = df) + geom_point(aes(x = A,y=B), size = 4) + geom_line(aes(x = A,y=B))
ggplot(aes(x = A, y = B), data = df) + geom_point(size = 4) + geom_line()&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;http://driftlessdata.space/courses/dsci310/Intro_to_ggplot2_files/figure-html/unnamed-chunk-10-1.png&#34; width=&#34;432&#34; style=&#34;display: block; margin: auto;&#34; /&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;TASK:&lt;/strong&gt; Re-create the following plots. What happens if you try to map variable &lt;code&gt;C&lt;/code&gt; to &lt;code&gt;geom_line()&lt;/code&gt; using the &lt;strong&gt;size&lt;/strong&gt; scale?&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;http://driftlessdata.space/courses/dsci310/Intro_to_ggplot2_files/figure-html/unnamed-chunk-11-1.png&#34; width=&#34;432&#34; /&gt;&lt;img src=&#34;http://driftlessdata.space/courses/dsci310/Intro_to_ggplot2_files/figure-html/unnamed-chunk-11-2.png&#34; width=&#34;432&#34; /&gt;&lt;img src=&#34;http://driftlessdata.space/courses/dsci310/Intro_to_ggplot2_files/figure-html/unnamed-chunk-11-3.png&#34; width=&#34;432&#34; /&gt;&lt;img src=&#34;http://driftlessdata.space/courses/dsci310/Intro_to_ggplot2_files/figure-html/unnamed-chunk-11-4.png&#34; width=&#34;432&#34; /&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;facets&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Facets&lt;/h3&gt;
&lt;p&gt;&lt;em&gt;Faceting&lt;/em&gt;, according to Wickham, is “a more general case of the techniques known as conditioning, trellising, and latticing, and produces small multiples showing different subsets of the data” (page 6). This conditioning is done by way of the &lt;code&gt;facet_grid()&lt;/code&gt; argument using formula, &lt;code&gt;~&lt;/code&gt;, syntax:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;ggplot(aes(x = A,y=B),data = df)  + geom_line(size=2)+ geom_point(size = 4) + facet_grid(.~D)
ggplot(aes(x = A,y=B),data = df)  + geom_line(size=2)+ geom_point(size = 4) + facet_grid(D~.)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;http://driftlessdata.space/courses/dsci310/Intro_to_ggplot2_files/figure-html/unnamed-chunk-13-1.png&#34; width=&#34;432&#34; /&gt;&lt;img src=&#34;http://driftlessdata.space/courses/dsci310/Intro_to_ggplot2_files/figure-html/unnamed-chunk-13-2.png&#34; width=&#34;432&#34; /&gt;&lt;/p&gt;
&lt;p&gt;The easiest way to change the labels is to change the levels of the &lt;code&gt;D&lt;/code&gt; factor:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;levels(df$D)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] &amp;quot;far&amp;quot;  &amp;quot;near&amp;quot;&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;levels(df$D) &amp;lt;- c(&amp;#39;Away&amp;#39;,&amp;#39;Home&amp;#39;)
ggplot(aes(x = A,y=B, color=D),data = df)  + geom_line(size=2)+ geom_point(size = 4) + facet_grid(.~D)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;http://driftlessdata.space/courses/dsci310/Intro_to_ggplot2_files/figure-html/unnamed-chunk-14-1.png&#34; width=&#34;384&#34; style=&#34;display: block; margin: auto;&#34; /&gt;&lt;/p&gt;
&lt;p&gt;Changing the labels without changing the underlying data requires use of a &lt;code&gt;labeller&lt;/code&gt; function, with is not exactly intuitive.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;bells-and-whistles&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Bells and whistles&lt;/h3&gt;
&lt;p&gt;Titles and axis labels are easily modified by way of the &lt;code&gt;ggtitle()&lt;/code&gt;, &lt;code&gt;xlab()&lt;/code&gt;, and &lt;code&gt;ylab()&lt;/code&gt; commands. Legend titles and labels are a little less intuitive, and require thought as to the &lt;strong&gt;scale&lt;/strong&gt; that is being shown, and the variable type that is being mapped. Changing these is by way of the &lt;code&gt;scale_*_*()&lt;/code&gt; function, where the first &lt;code&gt;*&lt;/code&gt; is the scale type and the second &lt;code&gt;*&lt;/code&gt; is the type of the variable being mapped.&lt;/p&gt;
&lt;p&gt;For example, suppose we want to change the default legend name and labels of the following graph: &lt;img src=&#34;http://driftlessdata.space/courses/dsci310/Intro_to_ggplot2_files/figure-html/unnamed-chunk-15-1.png&#34; width=&#34;432&#34; style=&#34;display: block; margin: auto;&#34; /&gt;&lt;/p&gt;
&lt;p&gt;There are &lt;em&gt;two&lt;/em&gt; scales involved in this visualization: &lt;strong&gt;shape&lt;/strong&gt; and &lt;strong&gt;color&lt;/strong&gt;, and they are being used to map a &lt;em&gt;discrete&lt;/em&gt; variable. Hence to modify the legend we should use &lt;code&gt;scale_shape_discrete()&lt;/code&gt; and &lt;code&gt;scale_color_discrete()&lt;/code&gt;. Note that if we only modify one at a time, two legends will appear reflecting the different modifications; this is not desirable. The names and labels must be identical for the two legends to merge:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;ggplot(data = df) + geom_point(aes(x = A,y=B, shape = D,color=D), size = 4) + 
    scale_shape_discrete(name=&amp;#39;Variable D&amp;#39;)
ggplot(data = df) + geom_point(aes(x = A,y=B, shape = D,color=D), size = 4) + 
    scale_color_discrete(labels=c(&amp;#39;TweedleDee&amp;#39;,&amp;#39;TweedleDum&amp;#39;))
ggplot(data = df) + geom_point(aes(x = A,y=B, shape = D,color=D), size = 4) + 
    scale_color_discrete(name=&amp;#39;Variable D&amp;#39;,labels=c(&amp;#39;TweedleDee&amp;#39;,&amp;#39;TweedleDum&amp;#39;)) + 
    scale_shape_discrete(name=&amp;#39;Variable D&amp;#39;,labels=c(&amp;#39;TweedleDee&amp;#39;,&amp;#39;TweedleDum&amp;#39;)) + 
    xlab(&amp;#39;Variable A&amp;#39;) + ylab(&amp;#39;Variable B&amp;#39;) + ggtitle(&amp;quot;Here&amp;#39;s a sweet title&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;http://driftlessdata.space/courses/dsci310/Intro_to_ggplot2_files/figure-html/unnamed-chunk-17-1.png&#34; width=&#34;432&#34; /&gt;&lt;img src=&#34;http://driftlessdata.space/courses/dsci310/Intro_to_ggplot2_files/figure-html/unnamed-chunk-17-2.png&#34; width=&#34;432&#34; /&gt;&lt;img src=&#34;http://driftlessdata.space/courses/dsci310/Intro_to_ggplot2_files/figure-html/unnamed-chunk-17-3.png&#34; width=&#34;432&#34; /&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>Midterm project</title>
      <link>http://driftlessdata.space/courses/dsci310/midterm/</link>
      <pubDate>Mon, 09 Oct 2017 00:00:00 +0000</pubDate>
      
      <guid>http://driftlessdata.space/courses/dsci310/midterm/</guid>
      <description>

&lt;p&gt;For this semester&amp;rsquo;s midterm project, we will be participating in the American Statistical Association&amp;rsquo;s &lt;a href=&#34;http://thisisstatistics.org/policedatachallenge&#34;&gt;Police Data Challenge&lt;/a&gt;. Read the information on the website for many more details.  For the midterm project, &lt;strong&gt;&lt;em&gt;all students&lt;/em&gt;&lt;/strong&gt; should visualize the Seattle data set.&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;p&gt;&lt;a href=&#34;http://thisisstatistics.org/wp-content/uploads/2017/09/Police-Data-Challenge-Rules.pdf&#34;&gt;Detailed version of the rules&lt;/a&gt;.&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;Fill out &lt;a href=&#34;http://thisisstatistics.org/police-data-challenge-2017-declare-your-intent/&#34;&gt;declaration of intent form&lt;/a&gt; by &lt;strong&gt;&lt;em&gt;Friday, October 6&lt;/em&gt;&lt;/strong&gt;.  Only one team member needs to submit the form.  List me (Silas Bergen) as your sponsor.&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;From the website:&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;Awards will be given in three categories (1) Best Overall Analysis, (2) Best Visualization, and (3) Best Use of External Data.&lt;/p&gt;

&lt;p&gt;Winning teams will receive a $50 Amazon gift card, complimentary memberships to ASA, and a Police Data Challenge 2017 t-shirt, along with bragging rights and a chance to have an impact on local communities.&lt;/p&gt;

&lt;p&gt;Winners also will be profiled and promoted to ASA&amp;rsquo;s membership of leading statisticians and data scientists in academia, industry, business, and government, and through ASA&amp;rsquo;s public education campaign, ThisisStatistics. Second and third place winners will also be recognized.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;###Requirements for the competition&lt;/p&gt;

&lt;p&gt;Prepare the materials that you need to submit to the competition: PowerPoint presentation with up to 10 slides, and document with $\leq 500$ words detailing your process.  Each team should submit these files by Nov 3.&lt;/p&gt;

&lt;p&gt;###Additional requirements for DSCI 310 Midterm&lt;/p&gt;

&lt;p&gt;The main additional requirement is to use Census data &lt;em&gt;to some extent&lt;/em&gt; in your project.  One way is to merge Census Tract information with the Tract information in the Seattle data file.  A very nice R package for downloading Census data is &lt;code&gt;tidycensus&lt;/code&gt;, especially the function &lt;code&gt;get_acs()&lt;/code&gt;.  This function makes use of the Census API, specifically reading in data from the &lt;a href=&#34;https://www.census.gov/programs-surveys/acs/about.html&#34;&gt;American Community Survey (ACS)&lt;/a&gt;.&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://www.census.gov/data/developers/data-sets/acs-5year.html&#34;&gt;More information on the ACS API&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://api.census.gov/data/2015/acs5/variables.html&#34;&gt;Complete list of 2011-2015 ACS variables&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://walkerke.github.io/tidycensus/articles/basic-usage.html&#34;&gt;Nice overview of &lt;code&gt;tidycensus&lt;/code&gt; by its author, Kyle Walker&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Additionally, each team will present their PowerPoint slides beginning on &lt;strong&gt;&lt;em&gt;October 27&lt;/em&gt;&lt;/strong&gt; (so really, the deadline to have your PowerPoint done is 10/27, not 11/3).&lt;/p&gt;

&lt;h3 id=&#34;rubrics-for-dsci-310-midterm&#34;&gt;Rubrics for DSCI 310 midterm&lt;/h3&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://www.dropbox.com/s/7h03rx03aqfuibz/GroupProjectRubric-Fall2017.docx?dl=0&#34;&gt;Rubric for the visualizations (50%)&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://www.dropbox.com/s/vap4vrwwcayqbub/GroupPresentationRubric-Fall2017.docx?dl=0&#34;&gt;Rubric for presentations (30%)&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://winona.az1.qualtrics.com/jfe/form/SV_4TOSbiNE6e3gzQ1&#34;&gt;Link to group member evaluation (20%)&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&#34;relevant-resources&#34;&gt;Relevant resources&lt;/h3&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://www.census.gov/geo/reference/geoidentifiers.html&#34;&gt;Understanding Census Geographic Identifiers&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&#34;group-assignments&#34;&gt;Group assignments&lt;/h3&gt;

&lt;p&gt;Professionally, you will not get to always choose your own groups.  For the midterm project you will be assigned into groups, which are listed below.  Divide the work, and conquer!&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Group presentation order:&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;4, 2, 7, 1, 9, 8, 6, 5, 3&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;p&gt;Group 1:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;Jack Barta&lt;/li&gt;
&lt;li&gt;Sam Meyer&lt;/li&gt;
&lt;li&gt;Mariah Quam&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;Group 2:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;Fengrui Xue&lt;/li&gt;
&lt;li&gt;Thomas Gathje&lt;/li&gt;
&lt;li&gt;Max Oelerking&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;Group 3:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;Kapil Khanal&lt;/li&gt;
&lt;li&gt;Luke Peacock&lt;/li&gt;
&lt;li&gt;Jimmy Hickey&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;Group 4:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;Will Diedrick&lt;/li&gt;
&lt;li&gt;Yulun Xu&lt;/li&gt;
&lt;li&gt;Adam Clemens&lt;/li&gt;
&lt;li&gt;Lauren Willkom&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;Group 5:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;Salman Quraishi&lt;/li&gt;
&lt;li&gt;Waheed Khan&lt;/li&gt;
&lt;li&gt;Linh Nguyen&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;Group 6:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;Nathan Smith&lt;/li&gt;
&lt;li&gt;Paul Boelter&lt;/li&gt;
&lt;li&gt;David Stampley&lt;/li&gt;
&lt;li&gt;Akif Khan&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;Group 7:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;Austin Ellingworth&lt;/li&gt;
&lt;li&gt;Brad Erickson&lt;/li&gt;
&lt;li&gt;Sam Dokkebakken&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;Group 8:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;Matthew Ladin&lt;/li&gt;
&lt;li&gt;McHale Dye&lt;/li&gt;
&lt;li&gt;Catherine Nead&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;Group 9:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;Stacey Miertschin&lt;/li&gt;
&lt;li&gt;Reagan Buske&lt;/li&gt;
&lt;li&gt;Ross Krueger&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;/ul&gt;
</description>
    </item>
    
    <item>
      <title>Play Day Task</title>
      <link>http://driftlessdata.space/courses/dsci310/playday1/</link>
      <pubDate>Wed, 13 Sep 2017 00:00:00 +0000</pubDate>
      
      <guid>http://driftlessdata.space/courses/dsci310/playday1/</guid>
      <description>&lt;p&gt;Consider the &lt;a href=&#34;https://www.dropbox.com/s/yaqv5afaz1rp9j6/MLB-Standings-2016-2017.xlsx?dl=0&#34;&gt;Major League Baseball Standings data&lt;/a&gt;.  There are two worksheets in this Excel file: one with 2016 standings, and one with 2017 standings.  The important variables in each are the team names &amp;trade;; actual winning percentage (W-L%); and predicted winning percentage (pythWPct), which is each team&amp;rsquo;s predicted winning percentage based on the number of points (&amp;ldquo;runs&amp;rdquo;) scored by and against that team.&lt;/p&gt;

&lt;p&gt;Questions to be answered (no restrictions!):&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;Which teams&amp;rsquo; winning percentages most improved the most from 2016-2017?  Which teams got much worse?&lt;/li&gt;
&lt;li&gt;Which teams are most underperforming and overperforming their predicted winning percentage in 2017?&lt;br /&gt;&lt;/li&gt;
&lt;/ul&gt;
</description>
    </item>
    
    <item>
      <title>A summer REU at Winona State</title>
      <link>http://driftlessdata.space/post/winstats/</link>
      <pubDate>Sun, 10 Sep 2017 00:00:00 -0500</pubDate>
      
      <guid>http://driftlessdata.space/post/winstats/</guid>
      <description>&lt;p&gt;This past summer, I along with my colleagues Chris Malone and Brant Deppa had the fantastic opportunity to host four students for a 10-week summer research experience for undergraduates (REU).  Winona State was awarded the REU by the &lt;a href=&#34;http://www.amstat.org/&#34;&gt;American Statistical Association&lt;/a&gt;, which had received &lt;a href=&#34;https://www.nsf.gov/awardsearch/showAward?AWD_ID=1560332&#34;&gt;a grant from the NSF&lt;/a&gt; to fund four students at each of nine sites over the course of three years (three different sites per year).&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;https://www.linkedin.com/in/meganaadland/&#34;&gt;Megan Aadland&lt;/a&gt; (South Dakota State), &lt;a href=&#34;https://www.linkedin.com/in/jenn-halbleib/&#34;&gt;Jenn Halbleib&lt;/a&gt; (Amherst), &lt;a href=&#34;https://www.linkedin.com/in/adriannakallis/&#34;&gt;Adrianna Kallis&lt;/a&gt; (Iowa State), and &lt;a href=&#34;https://www.linkedin.com/in/eva-tourangeau/&#34;&gt;Eva Tourangeau&lt;/a&gt; (Lawrence) were selected from a competitive, national pool of undergraduates.  Their primary task: to learn!  Their specific task was to partner with researchers at the &lt;a href=&#34;https://international.ipums.org/international/&#34;&gt;Integrated Public Use Microdata Series International (IPUMS-I)&lt;/a&gt; to develop data products and visualizations for IPUMS-I users.   Two students worked primarily on using multiple correspondence analysis to develop an index of household wealth, while the other two worked on an &lt;a href=&#34;https://public.tableau.com/views/IPUMS-IWorldInteractiveDashboard/Dashboard1?:embed=y&amp;amp;:display_count=yes&#34;&gt;interactive data visualization&lt;/a&gt; to summarize basic demographic information for countries of interest to IPUMS-I users.  Both projects required a lot of data cleaning after extracting the microdata from the &lt;a href=&#34;https://international.ipums.org/international-action/variables/group&#34;&gt;IPUMS-I query service&lt;/a&gt;!&lt;/p&gt;

&lt;p&gt;Along with their research, the students took several professional development trips to learn about applications of data analytics in the workplace.  These included visits to &lt;a href=&#34;https://www.mayoclinic.org/&#34;&gt;Mayo Clinic&lt;/a&gt;, &lt;a href=&#34;https://bethematch.org/&#34;&gt;Be the Match&lt;/a&gt;, &lt;a href=&#34;https://www.optum.com/&#34;&gt;Optum&lt;/a&gt;, and the &lt;a href=&#34;https://www.wilder.org/Pages/default.aspx&#34;&gt;Wilder Foundation&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;But it wasn&amp;rsquo;t all work!  Fun included:&lt;/p&gt;

&lt;p&gt;&lt;center&gt;
&lt;figure&gt;
&lt;img src=&#34;http://driftlessdata.space/img/saints_game.jpg&#34; width=&#34;500&#34;/&gt;
St. Paul Saints baseball game!&lt;br /&gt;
&lt;/figure&gt;
&lt;/center&gt;&lt;/p&gt;

&lt;p&gt;&lt;center&gt;
&lt;figure&gt;
&lt;img src=&#34;http://driftlessdata.space/img/pizza_farm.jpg&#34; width=&#34;400&#34;/&gt;
Suncrest pizza farm!&lt;br /&gt;
&lt;/figure&gt;
&lt;/center&gt;&lt;/p&gt;

&lt;p&gt;At the end of the summer, the students traveled to Baltimore to present &lt;a href=&#34;http://driftlessdata.space/files/JSM-Poster.pdf&#34;&gt;their&lt;/a&gt; &lt;a href=&#34;http://driftlessdata.space/files/JSM_Poster_Presentation.jpg&#34;&gt;research&lt;/a&gt; at the &lt;a href=&#34;https://ww2.amstat.org/meetings/jsm/2017/&#34;&gt;2017 Joint Statistical Meetings&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;The 10 weeks flew by!  The students were a joy to spend a summer with, and it is obvious that great things lie ahead for each of them.  The &lt;a href=&#34;https://drive.google.com/file/d/0B8hZWQ0xl_CkbTJHMFk5WTVicmc/view&#34;&gt;three REU sites for Summer 2018 are already selected&lt;/a&gt;, so go apply (or tell your students to apply)!&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>R Homework 1</title>
      <link>http://driftlessdata.space/courses/stat450/r_hw1/</link>
      <pubDate>Sun, 27 Aug 2017 00:00:00 +0000</pubDate>
      
      <guid>http://driftlessdata.space/courses/stat450/r_hw1/</guid>
      <description>&lt;p&gt;&lt;strong&gt;Due Friday, 9/8 by 11:59pm. Prepare your submission with R Markdown. Submit fully-knitted html, Word, or pdf to D2L by due date. You are encouraged to use this .Rmd file as your starting point for your submission.&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;In class, we considered the case of rolling two dice, one red and one white. Let &lt;span class=&#34;math inline&#34;&gt;\(Y\equiv\)&lt;/span&gt; the minimum of the two rolls.&lt;/p&gt;
&lt;ol style=&#34;list-style-type: decimal&#34;&gt;
&lt;li&gt;Define the probability mass function (pmf) in tabular format. The table is started for you, below. Fill in the appropriate entries for &lt;span class=&#34;math inline&#34;&gt;\(p(y)\)&lt;/span&gt;.&lt;/li&gt;
&lt;/ol&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr class=&#34;header&#34;&gt;
&lt;th&gt;&lt;span class=&#34;math inline&#34;&gt;\(y\)&lt;/span&gt;&lt;/th&gt;
&lt;th&gt;&lt;span class=&#34;math inline&#34;&gt;\(p(y)\)&lt;/span&gt;&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td&gt;1&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td&gt;2&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td&gt;3&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td&gt;4&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td&gt;5&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td&gt;6&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;ol start=&#34;2&#34; style=&#34;list-style-type: decimal&#34;&gt;
&lt;li&gt;&lt;p&gt;Graph this pmf.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Find &lt;span class=&#34;math inline&#34;&gt;\(\mu \equiv E(Y)\)&lt;/span&gt;.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Find &lt;span class=&#34;math inline&#34;&gt;\(\sigma^2 \equiv Var(Y)\)&lt;/span&gt;.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Find &lt;span class=&#34;math inline&#34;&gt;\(M_Y(t)\)&lt;/span&gt;, and create a plot of &lt;span class=&#34;math inline&#34;&gt;\(M_Y(t)\)&lt;/span&gt; as a function of &lt;span class=&#34;math inline&#34;&gt;\(t\)&lt;/span&gt; over the interval &lt;span class=&#34;math inline&#34;&gt;\([-1,1]\)&lt;/span&gt;. (Hint: first, write a function &lt;code&gt;m(t)&lt;/code&gt; that takes as argument &lt;code&gt;t&lt;/code&gt; and returns &lt;span class=&#34;math inline&#34;&gt;\(M_Y(t)\)&lt;/span&gt;, for any input &lt;span class=&#34;math inline&#34;&gt;\(t\)&lt;/span&gt;. Then, create a sequence of &lt;span class=&#34;math inline&#34;&gt;\(t-\)&lt;/span&gt;values over &lt;span class=&#34;math inline&#34;&gt;\([1,1]\)&lt;/span&gt; with the &lt;code&gt;seq()&lt;/code&gt; function, and use your function to evaluate &lt;span class=&#34;math inline&#34;&gt;\(M_Y(t)\)&lt;/span&gt; for each value in the sequence. Then plot this sequence with &lt;span class=&#34;math inline&#34;&gt;\(t\)&lt;/span&gt; on the x-axis and &lt;span class=&#34;math inline&#34;&gt;\(M_Y(t)\)&lt;/span&gt; on the y-axis. The function &lt;code&gt;exp(t)&lt;/code&gt; can be used to evaluate &lt;span class=&#34;math inline&#34;&gt;\(e^t\)&lt;/span&gt;.)&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Now write an &lt;code&gt;R&lt;/code&gt; function &lt;code&gt;one.Y()&lt;/code&gt; that simulates a single realization of &lt;span class=&#34;math inline&#34;&gt;\(Y\)&lt;/span&gt;. Using this function and &lt;code&gt;replicate()&lt;/code&gt;, generate 1000 realizations of &lt;span class=&#34;math inline&#34;&gt;\(Y\)&lt;/span&gt;. Graph the empirical pmf, and verify that is is similar to the theoretical one above.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Find the empirical mean &lt;span class=&#34;math inline&#34;&gt;\(\bar Y\)&lt;/span&gt; and variance &lt;span class=&#34;math inline&#34;&gt;\(S^2\)&lt;/span&gt; (use &lt;code&gt;mean()&lt;/code&gt; and &lt;code&gt;var()&lt;/code&gt;). How do they compare to &lt;span class=&#34;math inline&#34;&gt;\(\mu\)&lt;/span&gt; and &lt;span class=&#34;math inline&#34;&gt;\(\sigma^2\)&lt;/span&gt;?&lt;/p&gt;&lt;/li&gt;
&lt;/ol&gt;
</description>
    </item>
    
    <item>
      <title>R Homework 1</title>
      <link>http://driftlessdata.space/courses/stat450/r_hw1.knit/</link>
      <pubDate>Sun, 27 Aug 2017 00:00:00 +0000</pubDate>
      
      <guid>http://driftlessdata.space/courses/stat450/r_hw1.knit/</guid>
      <description>&lt;p&gt;&lt;strong&gt;Due Friday, 9/8 by 11:59pm.  Prepare your submission with R Markdown.  Submit fully-knitted html, Word, or pdf to D2L by due date.  You are encouraged to use this .Rmd file as your starting point for your submission.&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;In class, we considered the case of rolling two dice, one red and one white.  Let $Y\equiv$ the minimum of the two rolls.&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;Define the probability mass function (pmf) in tabular format.  The table is started for you, below.  Fill in the appropriate entries for $p(y)$.&lt;/li&gt;
&lt;/ol&gt;

&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;$y$&lt;/th&gt;
&lt;th&gt;$p(y)$&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;

&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;1&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;2&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;3&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;4&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;5&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;6&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;

&lt;ol&gt;
&lt;li&gt;&lt;p&gt;Graph this pmf.&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;Find $\mu \equiv E(Y)$.&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;Find $\sigma^2 \equiv Var(Y)$.&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;Find $M_Y(t)$, and create a plot of $M_Y(t)$ as a function of $t$ over the interval $[-1,1]$.  (Hint: first, write a function &lt;code&gt;m(t)&lt;/code&gt; that takes as argument &lt;code&gt;t&lt;/code&gt; and returns $M_Y(t)$, for any input $t$.  Then, create a sequence of $t-$values over $[1,1]$ with the &lt;code&gt;seq()&lt;/code&gt; function, and use your function to evaluate $M_Y(t)$ for each value in the sequence.  Then plot this sequence with $t$ on the x-axis and $M_Y(t)$ on the y-axis.  The function &lt;code&gt;exp(t)&lt;/code&gt; can be used to evaluate $e^t$.)&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;Now write an &lt;code&gt;R&lt;/code&gt; function &lt;code&gt;one.Y()&lt;/code&gt; that simulates a single realization of $Y$.  Using this function and &lt;code&gt;replicate()&lt;/code&gt;, generate 1000 realizations of $Y$.  Graph the empirical pmf, and verify that is is similar to the theoretical one above.&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;Find the empirical mean $\bar Y$ and variance $S^2$ (use &lt;code&gt;mean()&lt;/code&gt; and &lt;code&gt;var()&lt;/code&gt;).  How do they compare to $\mu$ and $\sigma^2$?&lt;/p&gt;&lt;/li&gt;
&lt;/ol&gt;
</description>
    </item>
    
  </channel>
</rss>
